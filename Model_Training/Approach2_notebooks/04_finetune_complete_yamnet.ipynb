{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2443a157",
   "metadata": {},
   "source": [
    "Load pre-trained YAMNet, replace classification head, unfreeze all layers, and train end-to-end with low learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Suppress warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Configuration\n",
    "PROCESSED_ROOT = '../data/processed'\n",
    "METADATA_PATH = os.path.join(PROCESSED_ROOT, 'processed_frames_metadata.csv')\n",
    "FEATURES_DIR = '../data/approach2/features'\n",
    "MODELS_DIR = '../models/models_approach2/yamnet_finetuned'\n",
    "RESULTS_DIR = '../results/results_approach2/yamnet_finetuned'\n",
    "YAMNET_MODEL_HANDLE = 'https://tfhub.dev/google/yamnet/1'\n",
    "\n",
    "TARGET_SR = 16000\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "INITIAL_LR = 1e-5  # Very low for fine-tuning\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "\n",
    "print(\"\\nLoading data splits...\")\n",
    "\n",
    "# Load label mapping\n",
    "label_mapping = np.load(os.path.join(FEATURES_DIR, 'label_mapping.npy'),\n",
    "                       allow_pickle=True).item()\n",
    "categories = label_mapping['categories']\n",
    "num_classes = len(categories)\n",
    "\n",
    "print(f\"Classes: {categories}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Load metadata for train/val/test splits\n",
    "train_meta = pd.read_csv(os.path.join(FEATURES_DIR, 'train_metadata.csv'))\n",
    "val_meta = pd.read_csv(os.path.join(FEATURES_DIR, 'val_metadata.csv'))\n",
    "test_meta = pd.read_csv(os.path.join(FEATURES_DIR, 'test_metadata.csv'))\n",
    "\n",
    "print(f\"\\nDataset splits:\")\n",
    "print(f\"  Training:   {len(train_meta)} frames\")\n",
    "print(f\"  Validation: {len(val_meta)} frames\")\n",
    "print(f\"  Test:       {len(test_meta)} frames\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Create TensorFlow Datasets \n",
    "print(\"\\nCreating TensorFlow datasets...\")\n",
    "\n",
    "def load_all_frames(metadata_df, label='train'):\n",
    "    \"\"\"Load all frames into memory (works for reasonably-sized datasets).\"\"\"\n",
    "    print(f\"  Loading {label} frames into memory...\")\n",
    "    audio_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in metadata_df.iterrows():\n",
    "        try:\n",
    "            audio = np.load(row['frame_path']).astype(np.float32)\n",
    "            audio_data.append(audio)\n",
    "            labels.append(int(row['label']))\n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Could not load {row['frame_path']}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    audio_data = np.array(audio_data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    print(f\"    Loaded {len(audio_data)} frames\")\n",
    "    return audio_data, labels\n",
    "\n",
    "# Load all data into memory\n",
    "train_X, train_y = load_all_frames(train_meta, 'training')\n",
    "val_X, val_y = load_all_frames(val_meta, 'validation')\n",
    "test_X, test_y = load_all_frames(test_meta, 'test')\n",
    "\n",
    "# Create tf.data.Dataset from in-memory data (FIXED: Proper shape inference)\n",
    "def create_dataset_from_arrays(X, y, batch_size, shuffle=True, seed=RANDOM_SEED):\n",
    "    \"\"\"Create tf.data.Dataset from numpy arrays with proper shape.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(X), seed=seed)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "train_dataset = create_dataset_from_arrays(train_X, train_y, BATCH_SIZE, shuffle=True)\n",
    "val_dataset = create_dataset_from_arrays(val_X, val_y, BATCH_SIZE, shuffle=False)\n",
    "test_dataset = create_dataset_from_arrays(test_X, test_y, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"TensorFlow datasets created with proper shape inference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ea4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build Fine-Tuning Model\n",
    "print(\"\\nBuilding fine-tuning model architecture...\")\n",
    "\n",
    "class YAMNetFineTuned(keras.Model):\n",
    "    \"\"\"\n",
    "    YAMNet model with custom classification head.\n",
    "    All layers are trainable for end-to-end fine-tuning.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, yamnet_model_handle):\n",
    "        super(YAMNetFineTuned, self).__init__()\n",
    "        \n",
    "        # Load YAMNet\n",
    "        self.yamnet = hub.KerasLayer(\n",
    "            yamnet_model_handle,\n",
    "            trainable=True,  # Make YAMNet layers trainable\n",
    "            name='yamnet'\n",
    "        )\n",
    "        \n",
    "        # Custom classification head\n",
    "        self.classifier = keras.Sequential([\n",
    "            layers.Dense(256, activation='relu', name='fc1'),\n",
    "            layers.BatchNormalization(name='bn1'),\n",
    "            layers.Dropout(0.3, name='dropout1'),\n",
    "            layers.Dense(128, activation='relu', name='fc2'),\n",
    "            layers.BatchNormalization(name='bn2'),\n",
    "            layers.Dropout(0.2, name='dropout2'),\n",
    "            layers.Dense(num_classes, activation='softmax', name='output')\n",
    "        ], name='classifier')\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"Process batch of waveforms through YAMNet.\"\"\"\n",
    "        # Input shape: (batch_size, 15360) for 0.96s at 16kHz\n",
    "        \n",
    "        # Process each waveform through YAMNet\n",
    "        def process_single_waveform(waveform):\n",
    "            # YAMNet expects 1D audio\n",
    "            scores, embeddings, spectrogram = self.yamnet(waveform)\n",
    "            # embeddings shape: (num_frames, 1024)\n",
    "            # Average across temporal dimension\n",
    "            embedding = tf.reduce_mean(embeddings, axis=0)\n",
    "            return embedding\n",
    "        \n",
    "        # Apply to batch\n",
    "        embeddings = tf.map_fn(\n",
    "            process_single_waveform,\n",
    "            inputs,\n",
    "            fn_output_signature=tf.float32\n",
    "        )\n",
    "        \n",
    "        # Pass through classifier\n",
    "        outputs = self.classifier(embeddings, training=training)\n",
    "        return outputs\n",
    "\n",
    "# Build model\n",
    "print(\"Building YAMNet fine-tuning model...\")\n",
    "model = YAMNetFineTuned(num_classes, YAMNET_MODEL_HANDLE)\n",
    "\n",
    "# Build by calling with dummy input\n",
    "dummy_input = tf.random.normal([1, int(TARGET_SR * 0.96)])\n",
    "_ = model(dummy_input)\n",
    "\n",
    "print(f\"Model built\")\n",
    "print(f\"  Total parameters: {model.count_params():,}\")\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_count = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
    "print(f\"  Trainable parameters: {trainable_count:,}\")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edacf01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compile Model\n",
    "\n",
    "print(\"\\nCompiling model...\")\n",
    "\n",
    "# Calculate class weights for imbalanced data\n",
    "class_counts = pd.Series(train_y).value_counts().sort_index()\n",
    "total_samples = len(train_y)\n",
    "class_weights = {i: total_samples / (num_classes * count) \n",
    "                for i, count in enumerate(class_counts)}\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Optimizer with low learning rate for fine-tuning\n",
    "optimizer = keras.optimizers.Adam(learning_rate=INITIAL_LR)\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Model compiled with learning rate: {INITIAL_LR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Callbacks\n",
    "print(\"\\nSetting up callbacks...\")\n",
    "\n",
    "# Model checkpoint\n",
    "checkpoint_path = os.path.join(MODELS_DIR, 'best_model.keras')\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Learning rate reduction\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# CSV logger\n",
    "csv_logger = keras.callbacks.CSVLogger(\n",
    "    os.path.join(RESULTS_DIR, 'training_log.csv')\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint_callback,\n",
    "    early_stopping,\n",
    "    lr_scheduler,\n",
    "    csv_logger\n",
    "]\n",
    "\n",
    "print(f\"Callbacks configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train Model\n",
    "print(\"\\nTraining model...\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Initial learning rate: {INITIAL_LR}\")\n",
    "print(f\"  Class weights: Enabled\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60fd328",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Plot Training History\n",
    "print(\"\\nPlotting training history...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'training_history.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training history saved to {RESULTS_DIR}/training_history.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fa4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Evaluate on Test Set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "\n",
    "# Load best model\n",
    "model = keras.models.load_model(checkpoint_path, custom_objects={'YAMNetFineTuned': YAMNetFineTuned})\n",
    "print(f\"Loaded best model from {checkpoint_path}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(test_X, verbose=0)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = np.mean(test_y == y_pred)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"-\"*70)\n",
    "report = classification_report(test_y, y_pred, target_names=categories, digits=4)\n",
    "print(report)\n",
    "\n",
    "# Save classification report\n",
    "report_dict = classification_report(test_y, y_pred, target_names=categories, \n",
    "                                   output_dict=True)\n",
    "with open(os.path.join(RESULTS_DIR, 'classification_report.json'), 'w') as f:\n",
    "    json.dump(report_dict, f, indent=2)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_y, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=categories, yticklabels=categories,\n",
    "           cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Fine-Tuned YAMNet (Test Set)', \n",
    "         fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'confusion_matrix_test.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Confusion matrix saved to {RESULTS_DIR}/confusion_matrix_test.png\")\n",
    "\n",
    "# Per-class metrics\n",
    "print(\"\\nPer-class Performance:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Class':<20s} {'Precision':>10s} {'Recall':>10s} {'F1-Score':>10s} {'Support':>10s}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for cat in categories:\n",
    "    precision = report_dict[cat]['precision']\n",
    "    recall = report_dict[cat]['recall']\n",
    "    f1 = report_dict[cat]['f1-score']\n",
    "    support = report_dict[cat]['support']\n",
    "    print(f\"{cat:<20s} {precision:>10.4f} {recall:>10.4f} {f1:>10.4f} {support:>10.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ec066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Compare with Baseline Classifiers\n",
    "print(\"\\nComparing with baseline classifiers...\")\n",
    "\n",
    "comparison_file = '../results/model_comparison.csv'\n",
    "if os.path.exists(comparison_file):\n",
    "    baseline_df = pd.read_csv(comparison_file)\n",
    "    \n",
    "    # Add fine-tuned YAMNet results\n",
    "    yamnet_results = {\n",
    "        'Model': 'Fine-Tuned YAMNet',\n",
    "        'Accuracy': report_dict['accuracy'],\n",
    "        'Precision': report_dict['weighted avg']['precision'],\n",
    "        'Recall': report_dict['weighted avg']['recall'],\n",
    "        'F1-Score': report_dict['weighted avg']['f1-score']\n",
    "    }\n",
    "    \n",
    "    comparison_df = pd.concat([baseline_df, pd.DataFrame([yamnet_results])], \n",
    "                              ignore_index=True)\n",
    "    comparison_df = comparison_df.sort_values('F1-Score', ascending=False)\n",
    "    \n",
    "    print(\"\\nModel Comparison (including Fine-Tuned YAMNet):\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    comparison_df.to_csv(os.path.join(RESULTS_DIR, 'final_model_comparison.csv'), \n",
    "                        index=False)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        sorted_df = comparison_df.sort_values(metric)\n",
    "        \n",
    "        colors = ['coral' if model == 'Fine-Tuned YAMNet' else 'steelblue' \n",
    "                 for model in sorted_df['Model']]\n",
    "        \n",
    "        ax.barh(sorted_df['Model'], sorted_df[metric], color=colors)\n",
    "        ax.set_xlabel(metric, fontsize=12)\n",
    "        ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlim([0, 1])\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        for i, v in enumerate(sorted_df[metric]):\n",
    "            ax.text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'final_comparison.png'), \n",
    "               dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Comparison saved to {RESULTS_DIR}/final_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eba136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Save Final Model\n",
    "print(\"\\nSaving final model...\")\n",
    "\n",
    "final_model_path = os.path.join(MODELS_DIR, 'yamnet_finetuned_final.keras')\n",
    "model.save(final_model_path)\n",
    "print(f\"Model saved to {final_model_path}\")\n",
    "\n",
    "# Save model configuration\n",
    "model_config = {\n",
    "    'model_type': 'YAMNet Fine-Tuned (Approach 2)',\n",
    "    'num_classes': num_classes,\n",
    "    'categories': categories,\n",
    "    'sample_rate': TARGET_SR,\n",
    "    'frame_duration': 0.96,\n",
    "    'total_parameters': int(model.count_params()),\n",
    "    'trainable_parameters': int(trainable_count),\n",
    "    'training_config': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs': EPOCHS,\n",
    "        'initial_lr': INITIAL_LR,\n",
    "        'optimizer': 'Adam',\n",
    "    },\n",
    "    'test_performance': {\n",
    "        'accuracy': float(test_accuracy),\n",
    "        'precision': float(report_dict['weighted avg']['precision']),\n",
    "        'recall': float(report_dict['weighted avg']['recall']),\n",
    "        'f1_score': float(report_dict['weighted avg']['f1-score'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(MODELS_DIR, 'model_config.json'), 'w') as f:\n",
    "    json.dump(model_config, f, indent=2)\n",
    "\n",
    "print(f\"Model configuration saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Summary\n",
    "print(f\"\\nSuccessfully fine-tuned complete YAMNet model\")\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"  Precision: {report_dict['weighted avg']['precision']:.4f}\")\n",
    "print(f\"  Recall:    {report_dict['weighted avg']['recall']:.4f}\")\n",
    "print(f\"  F1-Score:  {report_dict['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "print(f\"\\nModel Details:\")\n",
    "print(f\"  Total parameters: {model.count_params():,}\")\n",
    "print(f\"  Trainable parameters: {trainable_count:,}\")\n",
    "print(f\"  Model size: ~{os.path.getsize(final_model_path) / (1024*1024):.2f} MB\")\n",
    "\n",
    "print(f\"\\nSaved artifacts:\")\n",
    "print(f\"  - Model: {final_model_path}\")\n",
    "print(f\"  - Config: {MODELS_DIR}/model_config.json\")\n",
    "print(f\"  - Results: {RESULTS_DIR}/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
