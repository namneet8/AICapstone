{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673581fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.effects\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from scipy.signal import wiener\n",
    "\n",
    "try:\n",
    "    import noisereduce as nr\n",
    "    NOISE_REDUCE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    NOISE_REDUCE_AVAILABLE = False\n",
    "    print(\"Warning: noisereduce not available. Using scipy.signal.wiener as fallback.\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eefa1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR            = '../data/raw'\n",
    "EXPLORATION_CSV     = 'audio_data_exploration.csv'\n",
    "PROCESSED_ROOT      = '../data/processed'\n",
    "TARGET_SR           = 16000\n",
    "FRAME_SEC           = 0.96\n",
    "HOP_SEC             = 0.48\n",
    "\n",
    "SILENCE_RMS_THR     = 0.003  \n",
    "CLIP_MAX_AMP_THR    = 0.99\n",
    "LOW_SNR_THR         = 10.0  \n",
    "\n",
    "CATEGORY_RMS_TARGETS = {\n",
    "    'Glass_Breaking': 0.05,  \n",
    "    'Alarm_Clock': 0.08,    \n",
    "    'Car_Horn': 0.10,\n",
    "    'Gunshot': 0.10,\n",
    "    'Siren': 0.10\n",
    "}\n",
    "\n",
    "# Augmentation configuration \n",
    "AUGMENT_MULTIPLIERS = {\n",
    "    'Glass_Breaking': 6, \n",
    "    'Alarm_Clock': 5,    \n",
    "    'Siren': 3,         \n",
    "    'Car_Horn': 3,        \n",
    "    'Gunshot': 3         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5_hash(filepath: str) -> str:\n",
    "    \"\"\"Compute MD5 hash of a file.\"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def load_audio(filepath: str):\n",
    "    \"\"\"Load audio, force mono and target sample rate.\"\"\"\n",
    "    y, sr = librosa.load(filepath, sr=TARGET_SR, mono=True)\n",
    "    return y, sr\n",
    "\n",
    "def compute_rms(y: np.ndarray) -> float:\n",
    "    \"\"\"Compute RMS energy.\"\"\"\n",
    "    return np.sqrt(np.mean(y**2))\n",
    "\n",
    "def is_silent(y: np.ndarray, thr: float = SILENCE_RMS_THR) -> bool:\n",
    "    \"\"\"Return True if RMS is below the silence threshold.\"\"\"\n",
    "    return compute_rms(y) < thr\n",
    "\n",
    "def handle_clipping(y: np.ndarray, thr: float = CLIP_MAX_AMP_THR) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Scale down if max amplitude exceeds threshold.\n",
    "    Always enforce [-1, 1] range.\n",
    "    \"\"\"\n",
    "    max_amp = np.max(np.abs(y))\n",
    "    if max_amp >= thr:\n",
    "        y = y / (max_amp + 1e-8) * 0.95\n",
    "    return np.clip(y, -1.0, 1.0)\n",
    "\n",
    "def normalise_rms(y: np.ndarray, target: float, max_gain: float = 3.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Scale to a target RMS energy level with maximum gain limit.\n",
    "    FIXED: Added max_gain parameter to prevent over-amplification.\n",
    "    \"\"\"\n",
    "    current_rms = compute_rms(y)\n",
    "    if current_rms > 1e-8:\n",
    "        scale_factor = target / current_rms\n",
    "        # FIXED: Limit gain to prevent distortion\n",
    "        scale_factor = min(scale_factor, max_gain)\n",
    "        y = y * scale_factor\n",
    "    return y\n",
    "\n",
    "def pad_to_length(y: np.ndarray, sr: int, target_sec: float = FRAME_SEC) -> np.ndarray:\n",
    "    \"\"\"Zero-pad if shorter than target length.\"\"\"\n",
    "    target_samples = int(target_sec * sr)\n",
    "    if len(y) < target_samples:\n",
    "        y = np.pad(y, (0, target_samples - len(y)), mode='constant')\n",
    "    return y\n",
    "\n",
    "def reduce_noise(y: np.ndarray, sr: int) -> np.ndarray:\n",
    "    \"\"\"Apply moderate noise reduction.\"\"\"\n",
    "    if NOISE_REDUCE_AVAILABLE:\n",
    "        try:\n",
    "            y = nr.reduce_noise(\n",
    "                y=y, \n",
    "                sr=sr, \n",
    "                stationary=True, \n",
    "                prop_decrease=0.5,\n",
    "                time_constant_s=2.0\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: noisereduce failed ({str(e)}). Using Wiener filter.\")\n",
    "            y = wiener(y)\n",
    "    else:\n",
    "        y = wiener(y)\n",
    "    return y\n",
    "\n",
    "def extract_frames(y: np.ndarray, sr: int,\n",
    "                   frame_sec: float = FRAME_SEC,\n",
    "                   hop_sec: float = HOP_SEC) -> list:\n",
    "    \"\"\"Extract overlapping frames from audio.\"\"\"\n",
    "    frame_samples = int(frame_sec * sr)\n",
    "    hop_samples = int(hop_sec * sr)\n",
    "    \n",
    "    frames = []\n",
    "    for start in range(0, len(y) - frame_samples + 1, hop_samples):\n",
    "        frame = y[start:start + frame_samples]\n",
    "        frames.append(frame)\n",
    "    \n",
    "    if len(y) > frame_samples and (len(y) - frame_samples) % hop_samples != 0:\n",
    "        last_frame = y[-frame_samples:]\n",
    "        frames.append(last_frame)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def augment_frame(frame: np.ndarray, sr: int, category: str, n_augmentations: int) -> list:\n",
    "    \"\"\"\n",
    "    Generate augmented versions of a frame.\n",
    "    FIXED: Preserve RMS energy across augmentations.\n",
    "    \"\"\"\n",
    "    augmented = [frame.copy()]\n",
    "    original_rms = compute_rms(frame)\n",
    "    \n",
    "    for i in range(n_augmentations - 1):\n",
    "        aug = frame.copy()\n",
    "        \n",
    "        # 1. Time shift (circular)\n",
    "        shift_samples = np.random.randint(-len(aug)//4, len(aug)//4)\n",
    "        aug = np.roll(aug, shift_samples)\n",
    "        \n",
    "        # 2. Pitch shift (subtle)\n",
    "        n_steps = np.random.uniform(-1.0, 1.0)\n",
    "        try:\n",
    "            aug = librosa.effects.pitch_shift(aug, sr=sr, n_steps=n_steps)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        # 3. Add very subtle Gaussian noise\n",
    "        current_rms = compute_rms(aug)\n",
    "        noise_level = current_rms * 0.001\n",
    "        noise = np.random.normal(0, noise_level, len(aug))\n",
    "        aug = aug + noise\n",
    "        \n",
    "        # 4. FIXED: Restore original RMS to preserve energy\n",
    "        aug_rms = compute_rms(aug)\n",
    "        if aug_rms > 1e-8:\n",
    "            aug = aug * (original_rms / aug_rms)\n",
    "        \n",
    "        # 5. Safety clipping\n",
    "        aug = handle_clipping(aug)\n",
    "        \n",
    "        augmented.append(aug)\n",
    "    \n",
    "    return augmented\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab4534b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded exploration data: 843 files\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(EXPLORATION_CSV):\n",
    "    raise FileNotFoundError(f\"Exploration CSV not found: {EXPLORATION_CSV}\")  \n",
    "df_expl = pd.read_csv(EXPLORATION_CSV)\n",
    "print(f\"\\nLoaded exploration data: {len(df_expl)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580467f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 40 duplicate files → 803 unique files\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates by hash\n",
    "original_count = len(df_expl)\n",
    "df_expl = df_expl.drop_duplicates(subset='file_hash', keep='first')\n",
    "duplicates_removed = original_count - len(df_expl)\n",
    "print(f\"Removed {duplicates_removed} duplicate files → {len(df_expl)} unique files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1331e4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 803 files that loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Remove files that failed to load\n",
    "df_expl = df_expl[df_expl['load_success'] == True].copy()\n",
    "print(f\"Using {len(df_expl)} files that loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5750f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing files...\n"
     ]
    }
   ],
   "source": [
    "# Prepare output directories\n",
    "os.makedirs(PROCESSED_ROOT, exist_ok=True)\n",
    "for category in df_expl['category'].unique():\n",
    "    os.makedirs(os.path.join(PROCESSED_ROOT, category), exist_ok=True)\n",
    "\n",
    "# Initialize tracking\n",
    "processed_records = []\n",
    "stats = {\n",
    "    'files_processed': 0,\n",
    "    'files_skipped_silent': 0,\n",
    "    'files_skipped_error': 0,\n",
    "    'frames_original': 0,\n",
    "    'frames_augmented': 0,\n",
    "    'frames_skipped_silent': 0\n",
    "}\n",
    "    \n",
    "skipped_details = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb0ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 803/803 [02:35<00:00,  5.16it/s]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nProcessing files...\")\n",
    "\n",
    "# Process each file\n",
    "for _, row in tqdm(df_expl.iterrows(), total=len(df_expl), desc=\"Processing\"):\n",
    "    category = row['category']\n",
    "    filename = row['file']\n",
    "    filepath = os.path.join(DATA_DIR, category, filename)\n",
    "    original_snr = row.get('snr_db', np.inf)\n",
    "        \n",
    "    if not os.path.exists(filepath):\n",
    "        stats['files_skipped_error'] += 1\n",
    "        skipped_details.append(f\"{filename}: File not found\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        # 1. Load audio (mono, 16kHz)\n",
    "        y, sr = load_audio(filepath)\n",
    "            \n",
    "        # 2. Check for silence at file level\n",
    "        if is_silent(y):\n",
    "            stats['files_skipped_silent'] += 1\n",
    "            skipped_details.append(f\"{filename}: Silent file (RMS={compute_rms(y):.6f})\")\n",
    "            continue\n",
    "            \n",
    "        # 3. Apply noise reduction for low-SNR Siren files only\n",
    "        if category == 'Siren' and original_snr < LOW_SNR_THR:\n",
    "            y = reduce_noise(y, sr)\n",
    "            \n",
    "        # 4. Fix clipping at file level\n",
    "        y = handle_clipping(y)\n",
    "            \n",
    "        # 5. Pad if needed (before frame extraction)\n",
    "        y = pad_to_length(y, sr)\n",
    "            \n",
    "        stats['files_processed'] += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        stats['files_skipped_error'] += 1\n",
    "        skipped_details.append(f\"{filename}: Error loading - {str(e)}\")\n",
    "        continue\n",
    "        \n",
    "    # FRAME-LEVEL PROCESSING \n",
    "    frames = extract_frames(y, sr)\n",
    "    augment_factor = AUGMENT_MULTIPLIERS.get(category, 3)\n",
    "    target_rms = CATEGORY_RMS_TARGETS.get(category, 0.10)\n",
    "        \n",
    "    for frame_idx, frame in enumerate(frames):\n",
    "        # Check frame for silence BEFORE normalization\n",
    "        if is_silent(frame):\n",
    "            stats['frames_skipped_silent'] += augment_factor  # Count all would-be augmentations\n",
    "            continue\n",
    "            \n",
    "        # Normalize frame ONCE before augmentation\n",
    "        frame_normalized = normalise_rms(frame, target_rms, max_gain=3.0)\n",
    "        frame_normalized = handle_clipping(frame_normalized)\n",
    "            \n",
    "        # Double-check after normalization (catches edge cases)\n",
    "        if is_silent(frame_normalized):\n",
    "            stats['frames_skipped_silent'] += augment_factor\n",
    "            continue\n",
    "            \n",
    "        # Generate augmented versions\n",
    "        augmented_frames = augment_frame(frame_normalized, sr, category, augment_factor)\n",
    "            \n",
    "        for aug_idx, aug_frame in enumerate(augmented_frames):\n",
    "            # No silence check needed - already verified before augmentation\n",
    "            # and RMS is preserved during augmentation\n",
    "                \n",
    "            # Final safety clipping\n",
    "            aug_frame = handle_clipping(aug_frame)\n",
    "                \n",
    "            # Save frame\n",
    "            frame_name = f\"{os.path.splitext(filename)[0]}_f{frame_idx}_a{aug_idx}.npy\"\n",
    "            cat_out_dir = os.path.join(PROCESSED_ROOT, category)\n",
    "            frame_path = os.path.join(cat_out_dir, frame_name)\n",
    "                \n",
    "            np.save(frame_path, aug_frame)\n",
    "                \n",
    "            # Record metadata\n",
    "            processed_records.append({\n",
    "                'category': category,\n",
    "                'original_file': filename,\n",
    "                'frame_idx': frame_idx,\n",
    "                'aug_idx': aug_idx,\n",
    "                'is_augmented': aug_idx > 0,\n",
    "                'frame_path': frame_path,\n",
    "                'duration_sec': FRAME_SEC\n",
    "            })\n",
    "                \n",
    "            if aug_idx == 0:\n",
    "                stats['frames_original'] += 1\n",
    "            else:\n",
    "                stats['frames_augmented'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "100751db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSING COMPLETE\n",
      "\n",
      "Saved 11906 total frames\n",
      "  - Original frames: 3243\n",
      "  - Augmented frames: 8663\n",
      "  - Metadata: ../data/processed\\processed_frames_metadata.csv\n",
      "\n",
      "Frames per category:\n",
      "  Alarm_Clock    : 2450 (490 original + 1960 augmented)\n",
      "  Car_Horn       : 2325 (775 original + 1550 augmented)\n",
      "  Glass_Breaking : 2394 (399 original + 1995 augmented)\n",
      "  Gunshot        : 2355 (785 original + 1570 augmented)\n",
      "  Siren          : 2382 (794 original + 1588 augmented)\n",
      "\n",
      "Class balance ratio: 1.05 (max/min)\n",
      "  Dataset is reasonably balanced\n",
      "\n",
      "File processing:\n",
      "  - Processed: 802\n",
      "  - Skipped (silent): 1\n",
      "  - Skipped (error): 0\n",
      "\n",
      "Frame filtering:\n",
      "  - Frames skipped (silent): 2095\n",
      "\n",
      "Skipped files details (first 10):\n",
      "  - -74dab6wYqU_30.wav: Silent file (RMS=0.002488)\n"
     ]
    }
   ],
   "source": [
    " # SAVE METADATA \n",
    "meta_df = pd.DataFrame(processed_records)\n",
    "meta_path = os.path.join(PROCESSED_ROOT, 'processed_frames_metadata.csv')\n",
    "meta_df.to_csv(meta_path, index=False)\n",
    "    \n",
    "# PRINT SUMMARY\n",
    "print(\"PREPROCESSING COMPLETE\")\n",
    "print(f\"\\nSaved {len(meta_df)} total frames\")\n",
    "print(f\"  - Original frames: {stats['frames_original']}\")\n",
    "print(f\"  - Augmented frames: {stats['frames_augmented']}\")\n",
    "print(f\"  - Metadata: {meta_path}\")\n",
    "print(f\"\\nFrames per category:\")\n",
    "category_counts = meta_df['category'].value_counts().sort_index()\n",
    "for cat, count in category_counts.items():\n",
    "    orig = len(meta_df[(meta_df['category'] == cat) & (meta_df['aug_idx'] == 0)])\n",
    "    aug = count - orig\n",
    "    print(f\"  {cat:15s}: {count:4d} ({orig} original + {aug} augmented)\")\n",
    "    \n",
    "# Calculate balance\n",
    "max_count = category_counts.max()\n",
    "min_count = category_counts.min()\n",
    "balance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "print(f\"\\nClass balance ratio: {balance_ratio:.2f} (max/min)\")\n",
    "if balance_ratio > 2.0:\n",
    "    print(f\"  Dataset is imbalanced (ratio > 2.0)\")\n",
    "else:\n",
    "    print(f\"  Dataset is reasonably balanced\")\n",
    "    \n",
    "print(f\"\\nFile processing:\")\n",
    "print(f\"  - Processed: {stats['files_processed']}\")\n",
    "print(f\"  - Skipped (silent): {stats['files_skipped_silent']}\")\n",
    "print(f\"  - Skipped (error): {stats['files_skipped_error']}\")\n",
    "    \n",
    "print(f\"\\nFrame filtering:\")\n",
    "print(f\"  - Frames skipped (silent): {stats['frames_skipped_silent']}\")\n",
    "    \n",
    "if skipped_details:\n",
    "    print(f\"\\nSkipped files details (first 10):\")\n",
    "    for detail in skipped_details[:10]:\n",
    "        print(f\"  - {detail}\")\n",
    "    if len(skipped_details) > 10:\n",
    "        print(f\"  ... and {len(skipped_details) - 10} more\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
