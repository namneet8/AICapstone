{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c4e9b89",
   "metadata": {},
   "source": [
    "Combines YAMNet feature extractor with best classifier\n",
    "and exports as TensorFlow Lite model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2c6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e40dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "MODELS_DIR = '../models/models_approach1'\n",
    "TFLITE_DIR = '../models/models_approach1/tflite'\n",
    "RESULTS_DIR = '../results/results_approach1'\n",
    "YAMNET_MODEL_URL = 'https://tfhub.dev/google/yamnet/1'\n",
    "TARGET_SR = 16000\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "os.makedirs(TFLITE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"\\nTensorFlow version: {tf.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10194d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded label encoder\n",
      "  Classes: Alarm_Clock, Car_Horn, Glass_Breaking, Gunshot, Siren\n",
      "Loaded feature scaler\n",
      "\n",
      "Best model identified: XGBoost\n",
      "Loaded best classifier from: ../models/models_approach1\\xgboost_model.pkl\n",
      "\n",
      "Loading YAMNet model...\n",
      "YAMNet loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# LOAD TRAINED COMPONENTS\n",
    "\n",
    "# Load label encoder\n",
    "label_encoder = joblib.load(os.path.join(MODELS_DIR, 'label_encoder.pkl'))\n",
    "classes = label_encoder.classes_\n",
    "print(f\"\\nLoaded label encoder\")\n",
    "print(f\"  Classes: {', '.join(classes)}\")\n",
    "\n",
    "# Load scaler\n",
    "scaler = joblib.load(os.path.join(MODELS_DIR, 'feature_scaler.pkl'))\n",
    "print(f\"Loaded feature scaler\")\n",
    "\n",
    "# Determine best model from comparison results\n",
    "comparison_df = pd.read_csv(os.path.join(RESULTS_DIR, 'model_comparison.csv'))\n",
    "best_model_name = comparison_df.sort_values('Test F1', ascending=False).iloc[0]['Model']\n",
    "print(f\"\\nBest model identified: {best_model_name}\")\n",
    "\n",
    "# Load best model\n",
    "model_path = os.path.join(MODELS_DIR, f'{best_model_name.lower()}_model.pkl')\n",
    "best_classifier = joblib.load(model_path)\n",
    "print(f\"Loaded best classifier from: {model_path}\")\n",
    "\n",
    "# Load YAMNet\n",
    "print(f\"\\nLoading YAMNet model...\")\n",
    "yamnet_model = hub.load(YAMNET_MODEL_URL)\n",
    "print(f\"YAMNet loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af163a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING TENSORFLOW WRAPPER\n",
      "\n",
      "Building full pipeline model...\n",
      "Model wrapper created\n",
      "\n",
      "Testing model wrapper...\n",
      "Model test passed:\n",
      "  Input shape: (15360,)\n",
      "  Output probabilities shape: (5,)\n",
      "  Predicted class ID: 3\n",
      "  Predicted class name: Gunshot\n",
      "  Confidence: 0.6399\n"
     ]
    }
   ],
   "source": [
    "# BUILD TENSORFLOW MODEL WRAPPER\n",
    "print(\"BUILDING TENSORFLOW WRAPPER\")\n",
    "\n",
    "class YAMNetClassifierModel(tf.Module):\n",
    "    \"\"\"\n",
    "    Complete pipeline: Audio → YAMNet → Scaler → Classifier → Predictions\n",
    "    \n",
    "    IMPORTANT: This model expects audio input of exactly 0.96 seconds (15,360 samples at 16kHz)\n",
    "    For variable-length audio, preprocess into 0.96s segments before inference.\n",
    "    \"\"\"\n",
    "    def __init__(self, yamnet_model, scaler, classifier, label_encoder):\n",
    "        super().__init__()\n",
    "        self.yamnet_model = yamnet_model\n",
    "        self.scaler_mean = tf.constant(scaler.mean_, dtype=tf.float32)\n",
    "        self.scaler_scale = tf.constant(scaler.scale_, dtype=tf.float32)\n",
    "        self.classifier_type = type(classifier).__name__\n",
    "        self.label_encoder = label_encoder\n",
    "        self.class_names = tf.constant(label_encoder.classes_.tolist())\n",
    "        \n",
    "        # Store classifier parameters based on type\n",
    "        if self.classifier_type == 'LogisticRegression':\n",
    "            self.weights = tf.constant(classifier.coef_.T, dtype=tf.float32)\n",
    "            self.bias = tf.constant(classifier.intercept_, dtype=tf.float32)\n",
    "        else:\n",
    "            # For other classifiers, we'll need to use them in numpy mode\n",
    "            self.classifier = classifier\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[15360], dtype=tf.float32)])\n",
    "    def __call__(self, audio):\n",
    "        \"\"\"\n",
    "        Run inference on audio input\n",
    "        \n",
    "        Args:\n",
    "            audio: tf.Tensor of shape (15360,) - 0.96s at 16kHz\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with:\n",
    "                - probabilities: (5,) probability for each class\n",
    "                - predicted_class_id: scalar int\n",
    "                - predicted_class_name: string class name\n",
    "                - confidence: scalar float (max probability)\n",
    "        \"\"\"\n",
    "        # Extract YAMNet embeddings\n",
    "        scores, embeddings, spectrogram = self.yamnet_model(audio)\n",
    "        features = tf.reduce_mean(embeddings, axis=0, keepdims=True)\n",
    "        \n",
    "        # Scale features\n",
    "        features_scaled = (features - self.scaler_mean) / self.scaler_scale\n",
    "        \n",
    "        # Get predictions\n",
    "        if self.classifier_type == 'LogisticRegression':\n",
    "            # TF-only operations\n",
    "            logits = tf.matmul(features_scaled, self.weights) + self.bias\n",
    "            probabilities = tf.nn.softmax(logits)[0]\n",
    "        else:\n",
    "            # Use tf.py_function to wrap numpy operations\n",
    "            def sklearn_predict(features):\n",
    "                return self.classifier.predict_proba(features)[0].astype('float32')\n",
    "\n",
    "            probabilities = tf.py_function(sklearn_predict, [features_scaled], tf.float32)\n",
    "\n",
    "        \n",
    "        predicted_class_id = tf.argmax(probabilities)\n",
    "        predicted_class_name = self.class_names[predicted_class_id]\n",
    "        confidence = tf.reduce_max(probabilities)\n",
    "        \n",
    "        return {\n",
    "            'probabilities': probabilities,\n",
    "            'predicted_class_id': predicted_class_id,\n",
    "            'predicted_class_name': predicted_class_name,\n",
    "            'confidence': confidence\n",
    "        }\n",
    "\n",
    "# Build model\n",
    "print(\"\\nBuilding full pipeline model...\")\n",
    "full_model = YAMNetClassifierModel(yamnet_model, scaler, best_classifier, label_encoder)\n",
    "print(\"Model wrapper created\")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\nTesting model wrapper...\")\n",
    "test_audio = tf.random.normal([15360], dtype=tf.float32)\n",
    "test_output = full_model(test_audio)\n",
    "\n",
    "print(f\"Model test passed:\")\n",
    "print(f\"  Input shape: {test_audio.shape}\")\n",
    "print(f\"  Output probabilities shape: {test_output['probabilities'].shape}\")\n",
    "print(f\"  Predicted class ID: {test_output['predicted_class_id'].numpy()}\")\n",
    "print(f\"  Predicted class name: {test_output['predicted_class_name'].numpy().decode('utf-8')}\")\n",
    "print(f\"  Confidence: {test_output['confidence'].numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "531d3bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/models_approach1\\full_pipeline_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/models_approach1\\full_pipeline_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved full model to: ../models/models_approach1\\full_pipeline_savedmodel\n"
     ]
    }
   ],
   "source": [
    "# SAVE FULL MODEL\n",
    "saved_model_path = os.path.join(MODELS_DIR, 'full_pipeline_savedmodel')\n",
    "tf.saved_model.save(full_model, saved_model_path)\n",
    "print(f\"Saved full model to: {saved_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
