{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO TFLITE\n",
    "# Check if model is TFLite compatible\n",
    "if best_classifier.__class__.__name__ != 'LogisticRegression':\n",
    "    print(f\"\\nWARNING: {best_classifier.__class__.__name__} is not directly TFLite compatible!\")\n",
    "    print(\"Only Logistic Regression can be fully converted to TFLite.\")\n",
    "    \n",
    "    # Create a TFLite-compatible version with Logistic Regression\n",
    "    lr_model_path = os.path.join(MODELS_DIR, 'logistic_regression_model.pkl')\n",
    "    lr_classifier = joblib.load(lr_model_path)\n",
    "    print(f\"Loaded Logistic Regression model\")\n",
    "    \n",
    "    # Build LR version\n",
    "    lr_full_model = YAMNetClassifierModel(yamnet_model, scaler, lr_classifier, label_encoder)\n",
    "    print(\"Created Logistic Regression pipeline\")\n",
    "    \n",
    "    # Save LR version\n",
    "    lr_saved_model_path = os.path.join(MODELS_DIR, 'full_pipeline_lr_savedmodel')\n",
    "    tf.saved_model.save(lr_full_model, lr_saved_model_path)\n",
    "    print(f\"Saved LR model to: {lr_saved_model_path}\")\n",
    "    \n",
    "    model_to_convert = lr_full_model\n",
    "    conversion_note = \"logistic_regression\"\n",
    "else:\n",
    "    model_to_convert = full_model\n",
    "    conversion_note = best_model_name.lower()\n",
    "\n",
    "print(f\"\\nConverting {conversion_note} model to TFLite...\")\n",
    "\n",
    "# Create converter\n",
    "converter = tf.lite.TFLiteConverter.from_concrete_functions([\n",
    "    model_to_convert.__call__.get_concrete_function(\n",
    "        tf.TensorSpec(shape=[15360], dtype=tf.float32)\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d34386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization options\n",
    "\n",
    "# 1. Default (no optimization)\n",
    "print(\"\\n1. Default (Float32, no optimization)\")\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = os.path.join(TFLITE_DIR, f'model_{conversion_note}_float32.tflite')\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(f\"   Saved: {tflite_path}\")\n",
    "print(f\"   Size: {len(tflite_model) / 1024:.2f} KB\")\n",
    "\n",
    "# 2. Dynamic range quantization\n",
    "print(\"\\n2. Dynamic range quantization (Int8 weights, Float32 activations)\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized = converter.convert()\n",
    "tflite_quant_path = os.path.join(TFLITE_DIR, f'model_{conversion_note}_dynamic_quant.tflite')\n",
    "with open(tflite_quant_path, 'wb') as f:\n",
    "    f.write(tflite_quantized)\n",
    "print(f\"   Saved: {tflite_quant_path}\")\n",
    "print(f\"   Size: {len(tflite_quantized) / 1024:.2f} KB\")\n",
    "print(f\"   Compression: {(1 - len(tflite_quantized)/len(tflite_model)) * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb18b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST TFLITE MODELS\n",
    "def test_tflite_model(model_path, test_audio_np):\n",
    "    \"\"\"Test a TFLite model\"\"\"\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Set input\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_audio_np)\n",
    "    \n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get outputs\n",
    "    results = {}\n",
    "    for output in output_details:\n",
    "        results[output['name']] = interpreter.get_tensor(output['index'])\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Generate test audio\n",
    "test_audio_np = np.random.randn(15360).astype(np.float32)\n",
    "\n",
    "print(\"\\nTesting Float32 model...\")\n",
    "try:\n",
    "    results_float = test_tflite_model(tflite_path, test_audio_np)\n",
    "    print(\"Float32 model works!\")\n",
    "    print(f\"  Probabilities shape: {results_float['probabilities'].shape}\")\n",
    "    print(f\"  Predicted class: {results_float['predicted_class_id']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\nTesting Quantized model...\")\n",
    "try:\n",
    "    results_quant = test_tflite_model(tflite_quant_path, test_audio_np)\n",
    "    print(\"Quantized model works!\")\n",
    "    print(f\"  Probabilities shape: {results_quant['probabilities'].shape}\")\n",
    "    print(f\"  Predicted class: {results_quant['predicted_class_id']}\")\n",
    "    \n",
    "    # Compare outputs\n",
    "    if 'probabilities' in results_float and 'probabilities' in results_quant:\n",
    "        prob_diff = np.abs(results_float['probabilities'] - results_quant['probabilities']).max()\n",
    "        print(f\"\\nQuantization impact:\")\n",
    "        print(f\"  Max probability difference: {prob_diff:.6f}\")\n",
    "        if prob_diff < 0.01:\n",
    "            print(\"  Minimal impact from quantization\")\n",
    "        else:\n",
    "            print(\"  Moderate impact from quantization\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")\n",
    "\n",
    "# REAL AUDIO TEST \n",
    "try:\n",
    "    # Load a real test sample\n",
    "    test_features = np.load(os.path.join('../data/approach1/features', 'yamnet_features.npy'))\n",
    "    test_labels = np.load(os.path.join('../data/approach1/features', 'yamnet_labels.npy'))\n",
    "    test_metadata = pd.read_csv(os.path.join('../data/approach1/features', 'yamnet_features_metadata.csv'))\n",
    "    \n",
    "    # Pick a random sample\n",
    "    idx = np.random.randint(len(test_features))\n",
    "    sample_audio_path = test_metadata.iloc[idx]['frame_path']\n",
    "    true_label = test_labels[idx]\n",
    "    \n",
    "    print(f\"\\nTesting on: {os.path.basename(sample_audio_path)}\")\n",
    "    print(f\"True label: {true_label}\")\n",
    "    \n",
    "    # Load audio\n",
    "    sample_audio = np.load(sample_audio_path).astype(np.float32)\n",
    "    \n",
    "    # Test with TFLite\n",
    "    results = test_tflite_model(tflite_quant_path, sample_audio)\n",
    "    pred_class_id = results['predicted_class_id'][0]\n",
    "    pred_class_name = classes[pred_class_id]\n",
    "    confidence = results['probabilities'][0][pred_class_id]\n",
    "    \n",
    "    print(f\"\\nPrediction:\")\n",
    "    print(f\"  Class: {pred_class_name}\")\n",
    "    print(f\"  Confidence: {confidence:.4f}\")\n",
    "    print(f\"  Correct: {'✓' if pred_class_name == true_label else '✗'}\")\n",
    "    \n",
    "    print(f\"\\nAll probabilities:\")\n",
    "    for i, cls in enumerate(classes):\n",
    "        prob = results['probabilities'][0][i]\n",
    "        marker = \" ←\" if i == pred_class_id else \"\"\n",
    "        print(f\"  {cls:15s}: {prob:.4f}{marker}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not test on real audio: {e}\")\n",
    "\n",
    "# DEPLOYMENT GUIDE\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEPLOYMENT GUIDE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "deployment_info = f\"\"\"\n",
    "Models saved in: {TFLITE_DIR}\n",
    "\n",
    "Available models:\n",
    "1. model_{conversion_note}_float32.tflite - Full precision (larger, more accurate)\n",
    "2. model_{conversion_note}_dynamic_quant.tflite - Quantized (smaller, faster, slight accuracy loss)\n",
    "\n",
    "INPUT REQUIREMENTS:\n",
    "- Audio format: 16kHz, mono, float32\n",
    "- Duration: EXACTLY 0.96 seconds (15,360 samples)\n",
    "- Amplitude range: [-1.0, 1.0] (normalized)\n",
    "\n",
    "For variable-length audio:\n",
    "1. Resample to 16kHz\n",
    "2. Split into 0.96s segments (with overlap if needed)\n",
    "3. Run inference on each segment\n",
    "4. Aggregate results (e.g., max probability, voting)\n",
    "\n",
    "OUTPUT:\n",
    "- probabilities: [5] array of class probabilities\n",
    "- predicted_class_id: int (0-4)\n",
    "- predicted_class_name: string\n",
    "- confidence: float (max probability)\n",
    "\n",
    "Classes: {', '.join(classes)}\n",
    "\n",
    "PERFORMANCE:\n",
    "- Best model: {best_model_name}\n",
    "- Test F1-Score: {comparison_df.iloc[0]['Test F1']:.4f}\n",
    "- Test Accuracy: {comparison_df.iloc[0]['Test Acc']:.4f}\n",
    "\n",
    "INTEGRATION EXAMPLES:\n",
    "- Python: Use tf.lite.Interpreter\n",
    "- Android: Use TensorFlow Lite Android library\n",
    "- iOS: Use TensorFlow Lite iOS library\n",
    "- Web: Use TensorFlow.js (convert from SavedModel)\n",
    "- Edge devices: TFLite runtime\n",
    "\n",
    "See TensorFlow Lite documentation for platform-specific integration.\n",
    "\"\"\"\n",
    "\n",
    "print(deployment_info)\n",
    "\n",
    "# Save deployment guide\n",
    "guide_path = os.path.join(TFLITE_DIR, 'DEPLOYMENT_GUIDE.txt')\n",
    "with open(guide_path, 'w') as f:\n",
    "    f.write(deployment_info)\n",
    "print(f\"\\n✓ Saved deployment guide to: {guide_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PIPELINE BUILD COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"All models saved and tested\")\n",
    "print(\"Ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
