{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b10d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ TFLITE MODEL METADATA EMBEDDER\n",
      "======================================================================\n",
      "\n",
      "This script embeds comprehensive metadata into the .tflite model for mobile app integration\n",
      "\n",
      "üìù Step 0/3: Checking environment...\n",
      "\n",
      "üì¶ TensorFlow Version: 2.20.0\n",
      "üì¶ tflite-support Version: 0.1.0a1\n",
      "üì¶ flatbuffers Version: 25.9.23\n",
      "\n",
      "‚ö†Ô∏è tflite-support version 0.1.x detected. Limited functionality.\n",
      "   Strongly recommend upgrading: pip install tflite-support==0.4.4\n",
      "\n",
      "üìù Step 1/3: Verifying model structure...\n",
      "\n",
      "‚ö†Ô∏è Error verifying model: Didn't find op for builtin opcode 'PLACEHOLDER_FOR_GREATER_OP_CODES' version '1'. An older version of this builtin might be supported. Are you using an old TFLite binary with a newer model?\n",
      "Registration failed.\n",
      "\n",
      "\n",
      "üí° Possible causes:\n",
      "   - Model was created with a newer TensorFlow version than 2.20.0.\n",
      "   - Model contains unsupported operations.\n",
      "   Try the following:\n",
      "   1. Update TensorFlow: pip install --upgrade tensorflow\n",
      "   2. Reconvert the model using TensorFlow 2.20.0.\n",
      "   3. Install tflite-runtime: pip install tflite-runtime\n",
      "   4. Check for custom operations in the model.\n",
      "\n",
      "‚ö†Ô∏è Model verification failed. Attempting to proceed...\n",
      "   If metadata embedding fails, reconvert the model with TensorFlow 2.20.0.\n",
      "   Warning: Model may fail during inference due to unsupported operations.\n",
      "\n",
      "üìù Step 2/3: Embedding metadata into model...\n",
      "\n",
      "======================================================================\n",
      "EMBEDDING METADATA INTO MODEL\n",
      "======================================================================\n",
      "\n",
      "üìù Building metadata structure...\n",
      "üî® Compiling metadata flatbuffer...\n",
      "üì¶ Metadata buffer size: 1488 bytes\n",
      "üîß Embedding metadata into model...\n",
      "\n",
      "‚úÖ Metadata successfully embedded!\n",
      "üìÅ Output model: ../models/models_approach1/tflite\\model_with_metadata.tflite\n",
      "üìä Output size: 3356.84 KB\n",
      "\n",
      "üìù Step 3/3: Displaying embedded metadata...\n",
      "\n",
      "======================================================================\n",
      "EMBEDDED METADATA CONTENT\n",
      "======================================================================\n",
      "\n",
      "üìÑ JSON Metadata:\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"name\": \"YAMNet Audio Event Classifier\",\n",
      "  \"description\": \"Audio event detection model using YAMNet embeddings and Logistic Regression classifier. Detects: Alarm_Clock, Car_Horn, Glass_Breaking, Gunshot, Siren. Accuracy: 91.10%, F1: 0.9109. Designed for TensorFlow Lite 2.20.0. Mobile app integration: Preprocess audio to 16000Hz, mono, 15360 samples, normalized [-1.0, 1.0]. Output probabilities: Apply argmax for class index, use confidence threshold >0.6 to reduce false positives.\",\n",
      "  \"version\": \"1.0.0\",\n",
      "  \"subgraph_metadata\": [\n",
      "    {\n",
      "      \"name\": \"Classifier\",\n",
      "      \"description\": \"Audio classification subgraph. Input: [1, 15360] audio samples at 16000Hz. Output: [1, 5] probabilities over 5 classes.\",\n",
      "      \"input_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"input_tensor\",\n",
      "          \"description\": \"Input tensor expecting shape [1, 15360], dtype float32, mono audio at 16000Hz, 0.96s duration, normalized to [-1.0, 1.0]. Preprocessing: Resample audio to 16000Hz, convert to mono, normalize samples to [-1.0, 1.0], ensure exactly 15360 samples.\",\n",
      "          \"content\": {}\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"class_probabilities\",\n",
      "          \"description\": \"Output tensor with shape [1, 5], dtype float32, representing probability distribution over 5 classes: Alarm_Clock, Car_Horn, Glass_Breaking, Gunshot, Siren. Post-processing: Use argmax to get predicted class index (0 to 4). Apply confidence threshold >0.6 to filter predictions.\",\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0,\n",
      "              1.0,\n",
      "              1.0,\n",
      "              1.0,\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              0.0,\n",
      "              0.0,\n",
      "              0.0,\n",
      "              0.0,\n",
      "              0.0\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"author\": \"Your Name/Organization\",\n",
      "  \"license\": \"Apache-2.0\"\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "‚ú® PROCESS COMPLETE\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Model with metadata saved at: ../models/models_approach1/tflite\\model_with_metadata.tflite\n",
      "\n",
      "üìã Embedded metadata includes:\n",
      "  ‚úì Model name, version, description\n",
      "  ‚úì Author and license\n",
      "  ‚úì Input specifications (shape, dtype, preprocessing)\n",
      "  ‚úì Output specifications (shape, dtype, post-processing)\n",
      "  ‚úì Mobile app integration instructions\n",
      "\n",
      "üéØ Key Information for Mobile App:\n",
      "  ‚Ä¢ Classes: Alarm_Clock, Car_Horn, Glass_Breaking, Gunshot, Siren\n",
      "  ‚Ä¢ Input: [1, 15360] float32 audio samples\n",
      "  ‚Ä¢ Output: [1, 5] float32 probabilities\n",
      "  ‚Ä¢ Preprocessing: Resample to 16000Hz, mono, normalize to [-1.0, 1.0]\n",
      "  ‚Ä¢ Post-processing: Apply argmax, use confidence threshold >0.6\n",
      "  ‚Ä¢ Accuracy: 91.10%\n",
      "  ‚Ä¢ F1 Score: 0.9109\n",
      "\n",
      "‚ö†Ô∏è Note: Model verification failed. Ensure compatibility with TensorFlow Lite runtime for mobile inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import pkg_resources\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "TFLITE_DIR = '../models/models_approach1/tflite'\n",
    "MODEL_PATH = os.path.join(TFLITE_DIR, 'model_logistic_regression_dynamic_quant.tflite')\n",
    "OUTPUT_PATH = os.path.join(TFLITE_DIR, 'model_with_metadata.tflite')\n",
    "\n",
    "# Model information\n",
    "MODEL_INFO = {\n",
    "    \"name\": \"YAMNet Audio Event Classifier\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"description\": \"Audio event detection model using YAMNet embeddings and Logistic Regression classifier. Detects: Alarm_Clock, Car_Horn, Glass_Breaking, Gunshot, Siren.\",\n",
    "    \"license\": \"Apache-2.0\",\n",
    "    \"classes\": [\"Alarm_Clock\", \"Car_Horn\", \"Glass_Breaking\", \"Gunshot\", \"Siren\"],\n",
    "    \"sample_rate\": 16000,\n",
    "    \"input_duration_seconds\": 0.96,\n",
    "    \"input_samples\": 15360,\n",
    "    \"input_shape\": [1, 15360],\n",
    "    \"input_dtype\": \"float32\",\n",
    "    \"output_shape\": [1, 5],\n",
    "    \"output_dtype\": \"float32\",\n",
    "    \"accuracy\": 0.9110,\n",
    "    \"f1_score\": 0.9109,\n",
    "    \"confidence_threshold\": 0.6,\n",
    "    \"tflite_version\": \"2.20.0\"\n",
    "}\n",
    "\n",
    "def check_environment():\n",
    "    \"\"\"Check TensorFlow, tflite-support, and flatbuffers versions\"\"\"\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        from tflite_support import metadata as _metadata\n",
    "        import flatbuffers\n",
    "        tf_version = tf.__version__\n",
    "        tflite_support_version = pkg_resources.get_distribution(\"tflite-support\").version\n",
    "        flatbuffers_version = getattr(flatbuffers, '__version__', 'unknown')\n",
    "        print(f\"\\nüì¶ TensorFlow Version: {tf_version}\")\n",
    "        print(f\"üì¶ tflite-support Version: {tflite_support_version}\")\n",
    "        print(f\"üì¶ flatbuffers Version: {flatbuffers_version}\")\n",
    "        if tflite_support_version.startswith('0.1.'):\n",
    "            print(\"\\n‚ö†Ô∏è tflite-support version 0.1.x detected. Limited functionality.\")\n",
    "            print(\"   Strongly recommend upgrading: pip install tflite-support==0.4.4\")\n",
    "        if int(tf_version.split('.')[0]) < 2 or (int(tf_version.split('.')[0]) == 2 and int(tf_version.split('.')[1]) < 6):\n",
    "            print(\"\\n‚ö†Ô∏è TensorFlow version is too old. Minimum required: 2.6.0\")\n",
    "            print(\"   Upgrade with: pip install --upgrade tensorflow\")\n",
    "            return False\n",
    "        return True\n",
    "    except ImportError as e:\n",
    "        print(f\"\\n‚ùå Missing required package: {e}\")\n",
    "        print(\"   Install with: pip install tensorflow tflite-support flatbuffers\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Environment check failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def verify_model_structure():\n",
    "    \"\"\"Verify the model structure before embedding metadata\"\"\"\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\"\\n‚ùå Model file not found: {MODEL_PATH}\")\n",
    "        print(\"   Ensure the model file exists at the specified path.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        interpreter = tf.lite.Interpreter(model_path=MODEL_PATH)\n",
    "        interpreter.allocate_tensors()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"MODEL STRUCTURE VERIFICATION\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "\n",
    "        print(f\"\\nüì• INPUT TENSORS: {len(input_details)}\")\n",
    "        for i, detail in enumerate(input_details):\n",
    "            print(f\"  Input {i}: {detail['name']} - Shape: {detail['shape']} - Type: {detail['dtype']}\")\n",
    "\n",
    "        print(f\"\\nüì§ OUTPUT TENSORS: {len(output_details)}\")\n",
    "        for i, detail in enumerate(output_details):\n",
    "            print(f\"  Output {i}: {detail['name']} - Shape: {detail['shape']} - Type: {detail['dtype']}\")\n",
    "\n",
    "        print(\"\\n‚úÖ Model verification complete\")\n",
    "        print(\"=\"*70)\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è Error verifying model: {e}\")\n",
    "        print(\"\\nüí° Possible causes:\")\n",
    "        print(\"   - Model was created with a newer TensorFlow version than 2.20.0.\")\n",
    "        print(\"   - Model contains unsupported operations.\")\n",
    "        print(\"   Try the following:\")\n",
    "        print(\"   1. Update TensorFlow: pip install --upgrade tensorflow\")\n",
    "        print(\"   2. Reconvert the model using TensorFlow 2.20.0.\")\n",
    "        print(\"   3. Install tflite-runtime: pip install tflite-runtime\")\n",
    "        print(\"   4. Check for custom operations in the model.\")\n",
    "        return False\n",
    "\n",
    "def embed_metadata_into_model():\n",
    "    \"\"\"Embed comprehensive metadata directly into the TFLite model\"\"\"\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"EMBEDDING METADATA INTO MODEL\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        from tflite_support import metadata as _metadata\n",
    "        from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "        import flatbuffers\n",
    "\n",
    "        print(\"\\nüìù Building metadata structure...\")\n",
    "\n",
    "        model_meta = _metadata_fb.ModelMetadataT()\n",
    "        model_meta.name = MODEL_INFO[\"name\"]\n",
    "        model_meta.description = (\n",
    "            f\"{MODEL_INFO['description']} \"\n",
    "            f\"Accuracy: {MODEL_INFO['accuracy']:.2%}, F1: {MODEL_INFO['f1_score']:.4f}. \"\n",
    "            f\"Designed for TensorFlow Lite {MODEL_INFO['tflite_version']}. \"\n",
    "            f\"Mobile app integration: Preprocess audio to {MODEL_INFO['sample_rate']}Hz, \"\n",
    "            f\"mono, {MODEL_INFO['input_samples']} samples, normalized [-1.0, 1.0]. \"\n",
    "            f\"Output probabilities: Apply argmax for class index, use confidence threshold \"\n",
    "            f\">{MODEL_INFO['confidence_threshold']} to reduce false positives.\"\n",
    "        )\n",
    "        model_meta.version = MODEL_INFO[\"version\"]\n",
    "        model_meta.author = MODEL_INFO[\"author\"]\n",
    "        model_meta.license = MODEL_INFO[\"license\"]\n",
    "\n",
    "        input_meta = _metadata_fb.TensorMetadataT()\n",
    "        input_meta.name = \"input_tensor\"\n",
    "        input_meta.description = (\n",
    "            f\"Input tensor expecting shape {MODEL_INFO['input_shape']}, \"\n",
    "            f\"dtype {MODEL_INFO['input_dtype']}, mono audio at {MODEL_INFO['sample_rate']}Hz, \"\n",
    "            f\"{MODEL_INFO['input_duration_seconds']}s duration, normalized to [-1.0, 1.0]. \"\n",
    "            f\"Preprocessing: Resample audio to {MODEL_INFO['sample_rate']}Hz, convert to mono, \"\n",
    "            f\"normalize samples to [-1.0, 1.0], ensure exactly {MODEL_INFO['input_samples']} samples.\"\n",
    "        )\n",
    "        input_meta.content = _metadata_fb.ContentT()\n",
    "\n",
    "        output_metas = []\n",
    "        output_meta = _metadata_fb.TensorMetadataT()\n",
    "        output_meta.name = \"class_probabilities\"\n",
    "        output_meta.description = (\n",
    "            f\"Output tensor with shape {MODEL_INFO['output_shape']}, \"\n",
    "            f\"dtype {MODEL_INFO['output_dtype']}, representing probability distribution \"\n",
    "            f\"over {len(MODEL_INFO['classes'])} classes: {', '.join(MODEL_INFO['classes'])}. \"\n",
    "            f\"Post-processing: Use argmax to get predicted class index (0 to {len(MODEL_INFO['classes'])-1}). \"\n",
    "            f\"Apply confidence threshold >{MODEL_INFO['confidence_threshold']} to filter predictions.\"\n",
    "        )\n",
    "        stats = _metadata_fb.StatsT()\n",
    "        stats.max = [1.0] * len(MODEL_INFO[\"classes\"])\n",
    "        stats.min = [0.0] * len(MODEL_INFO[\"classes\"])\n",
    "        output_meta.stats = stats\n",
    "        output_metas.append(output_meta)\n",
    "\n",
    "        subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "        subgraph.name = \"Classifier\"\n",
    "        subgraph.description = (\n",
    "            f\"Audio classification subgraph. \"\n",
    "            f\"Input: {MODEL_INFO['input_shape']} audio samples at {MODEL_INFO['sample_rate']}Hz. \"\n",
    "            f\"Output: {MODEL_INFO['output_shape']} probabilities over {len(MODEL_INFO['classes'])} classes.\"\n",
    "        )\n",
    "        subgraph.inputTensorMetadata = [input_meta]\n",
    "        subgraph.outputTensorMetadata = output_metas\n",
    "        model_meta.subgraphMetadata = [subgraph]\n",
    "\n",
    "        print(\"üî® Compiling metadata flatbuffer...\")\n",
    "        b = flatbuffers.Builder(0)\n",
    "        b.Finish(\n",
    "            model_meta.Pack(b),\n",
    "            _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER\n",
    "        )\n",
    "        metadata_buf = b.Output()\n",
    "\n",
    "        print(f\"üì¶ Metadata buffer size: {len(metadata_buf)} bytes\")\n",
    "\n",
    "        print(\"üîß Embedding metadata into model...\")\n",
    "        with open(MODEL_PATH, 'rb') as f:\n",
    "            model_buffer = f.read()\n",
    "\n",
    "        populator = _metadata.MetadataPopulator.with_model_buffer(model_buffer)\n",
    "        populator.load_metadata_buffer(metadata_buf)\n",
    "        populator.populate()\n",
    "\n",
    "        with open(OUTPUT_PATH, 'wb') as f:\n",
    "            f.write(populator.get_model_buffer())\n",
    "\n",
    "        output_size = os.path.getsize(OUTPUT_PATH) / 1024\n",
    "        print(f\"\\n‚úÖ Metadata successfully embedded!\")\n",
    "        print(f\"üìÅ Output model: {OUTPUT_PATH}\")\n",
    "        print(f\"üìä Output size: {output_size:.2f} KB\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error embedding metadata: {e}\")\n",
    "        print(\"\\nüí° Troubleshooting steps:\")\n",
    "        print(\"   1. Upgrade tflite-support: pip install tflite-support==0.4.4\")\n",
    "        print(\"   2. Verify model compatibility with TensorFlow 2.20.0.\")\n",
    "        print(\"   3. Check write permissions: icacls \\\"\" + TFLITE_DIR + \"\\\" /grant:r \\\"%username%:F\\\" /t (Windows)\")\n",
    "        print(\"   4. Ensure the model file is not corrupted.\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def display_embedded_metadata():\n",
    "    \"\"\"Display the metadata embedded in the model\"\"\"\n",
    "    try:\n",
    "        from tflite_support import metadata as _metadata\n",
    "\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"EMBEDDED METADATA CONTENT\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        displayer = _metadata.MetadataDisplayer.with_model_file(OUTPUT_PATH)\n",
    "\n",
    "        print(\"\\nüìÑ JSON Metadata:\")\n",
    "        print(\"-\" * 70)\n",
    "        metadata_json = displayer.get_metadata_json()\n",
    "        if metadata_json:\n",
    "            import json\n",
    "            metadata_dict = json.loads(metadata_json)\n",
    "            print(json.dumps(metadata_dict, indent=2))\n",
    "        else:\n",
    "            print(\"No metadata found\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"\\n‚ö†Ô∏è tflite-support not available for metadata display\")\n",
    "        print(\"   Install with: pip install tflite-support\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è Could not display metadata: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üöÄ TFLITE MODEL METADATA EMBEDDER\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nThis script embeds comprehensive metadata into the .tflite model for mobile app integration\")\n",
    "\n",
    "    print(\"\\nüìù Step 0/3: Checking environment...\")\n",
    "    if not check_environment():\n",
    "        print(\"\\n‚ùå Environment check failed. Aborting.\")\n",
    "        print(\"   Run: pip install --upgrade tensorflow tflite-support flatbuffers\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüìù Step 1/3: Verifying model structure...\")\n",
    "    if not verify_model_structure():\n",
    "        print(\"\\n‚ö†Ô∏è Model verification failed. Attempting to proceed...\")\n",
    "        print(\"   If metadata embedding fails, reconvert the model with TensorFlow 2.20.0.\")\n",
    "        print(\"   Warning: Model may fail during inference due to unsupported operations.\")\n",
    "\n",
    "    print(\"\\nüìù Step 2/3: Embedding metadata into model...\")\n",
    "    if not embed_metadata_into_model():\n",
    "        print(\"\\n‚ùå Metadata embedding failed.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüìù Step 3/3: Displaying embedded metadata...\")\n",
    "    display_embedded_metadata()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚ú® PROCESS COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n‚úÖ Model with metadata saved at: {OUTPUT_PATH}\")\n",
    "    print(\"\\nüìã Embedded metadata includes:\")\n",
    "    print(\"  ‚úì Model name, version, description\")\n",
    "    print(\"  ‚úì Author and license\")\n",
    "    print(\"  ‚úì Input specifications (shape, dtype, preprocessing)\")\n",
    "    print(\"  ‚úì Output specifications (shape, dtype, post-processing)\")\n",
    "    print(\"  ‚úì Mobile app integration instructions\")\n",
    "    print(\"\\nüéØ Key Information for Mobile App:\")\n",
    "    print(f\"  ‚Ä¢ Classes: {', '.join(MODEL_INFO['classes'])}\")\n",
    "    print(f\"  ‚Ä¢ Input: {MODEL_INFO['input_shape']} {MODEL_INFO['input_dtype']} audio samples\")\n",
    "    print(f\"  ‚Ä¢ Output: {MODEL_INFO['output_shape']} {MODEL_INFO['output_dtype']} probabilities\")\n",
    "    print(f\"  ‚Ä¢ Preprocessing: Resample to {MODEL_INFO['sample_rate']}Hz, mono, normalize to [-1.0, 1.0]\")\n",
    "    print(f\"  ‚Ä¢ Post-processing: Apply argmax, use confidence threshold >{MODEL_INFO['confidence_threshold']}\")\n",
    "    print(f\"  ‚Ä¢ Accuracy: {MODEL_INFO['accuracy']:.2%}\")\n",
    "    print(f\"  ‚Ä¢ F1 Score: {MODEL_INFO['f1_score']:.4f}\")\n",
    "    print(\"\\n‚ö†Ô∏è Note: Model verification failed. Ensure compatibility with TensorFlow Lite runtime for mobile inference.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
