{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be04661c",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Approach 2: Fine-tune YAMNet End-to-End - TRAINING ONLY\n",
    "This script:\n",
    "1. Loads pre-trained YAMNet\n",
    "2. Replaces 521-class head with 5-class head\n",
    "3. Unfreezes all layers for fine-tuning\n",
    "4. Trains on raw audio with data augmentation\n",
    "5. Validates on validation set (NO TEST SET EVALUATION)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9cf12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_ROOT = '../data/split_processed'\n",
    "YAMNET_HANDLE = 'https://tfhub.dev/google/yamnet/1'\n",
    "MODELS_DIR = '../models/models_approach2/yamnet_finetuned'\n",
    "RESULTS_DIR = '../results/results_approach2/yamnet_finetuned'\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "FRAME_LENGTH = 15360\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-5\n",
    "PATIENCE_EARLY = 5\n",
    "PATIENCE_LR = 3\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c817328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== LOAD METADATA ====================\n",
    "CATEGORIES = ['alarm_clock','car_horn','glass_breaking','gunshot','siren']\n",
    "category_to_label = { \n",
    "    'alarm_clock':'Alarm_Clock', 'car_horn':'Car_Horn',\n",
    "    'glass_breaking':'Glass_Breaking','gunshot':'Gunshot','siren':'Siren'\n",
    "}\n",
    "label_to_id = {v:i for i,v in enumerate(sorted(category_to_label.values()))}\n",
    "id_to_label = {i:v for v,i in label_to_id.items()}\n",
    "\n",
    "print(f\"Classes: {list(label_to_id.keys())}\")\n",
    "print(f\"Label mapping: {label_to_id}\")\n",
    "\n",
    "# ==================== PREPARE FILE LISTS ====================\n",
    "def prepare_split(split):\n",
    "    paths, labels = [], []\n",
    "    for c in CATEGORIES:\n",
    "        d = os.path.join(SPLIT_ROOT, split, c)\n",
    "        if not os.path.exists(d): continue\n",
    "        for f in os.listdir(d):\n",
    "            if f.endswith('.npy'):\n",
    "                paths.append(os.path.join(d, f))\n",
    "                labels.append(label_to_id[category_to_label[c]])\n",
    "    return paths, labels\n",
    "\n",
    "train_paths, train_labels = prepare_split('train')\n",
    "val_paths, val_labels = prepare_split('val')\n",
    "\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Train: {len(train_paths):,} samples\")\n",
    "print(f\"  Val:   {len(val_paths):,} samples\")\n",
    "\n",
    "# Class distribution\n",
    "print(f\"\\nClass distribution:\")\n",
    "for split_name, labels in [('Train', train_labels), ('Val', val_labels)]:\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    for label_id, label_name in id_to_label.items():\n",
    "        count = labels.count(label_id)\n",
    "        pct = 100 * count / len(labels)\n",
    "        print(f\"  {label_name:<20} {count:>4} ({pct:>5.2f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== DATA LOADING FUNCTIONS ====================\n",
    "def load_audio(fp):\n",
    "    x = np.load(fp.numpy().decode())\n",
    "    if x.ndim > 1: x = x.flatten()\n",
    "    if len(x) < FRAME_LENGTH: x = np.pad(x, (0, FRAME_LENGTH-len(x)))\n",
    "    else: x = x[:FRAME_LENGTH]\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "def augment_audio(x):\n",
    "    noise = tf.random.normal(tf.shape(x), stddev=tf.random.uniform([], 0, 0.005))\n",
    "    gain = tf.random.uniform([], 0.8, 1.2)\n",
    "    return tf.clip_by_value(x*gain + noise, -1.0, 1.0)\n",
    "\n",
    "def preprocess(fp, y, aug=False):\n",
    "    audio = tf.py_function(load_audio, [fp], tf.float32)\n",
    "    audio.set_shape([FRAME_LENGTH])\n",
    "    if aug: audio = augment_audio(audio)\n",
    "    return audio, y\n",
    "\n",
    "def make_ds(paths, labels, aug=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if aug: ds = ds.shuffle(len(paths), seed=42)\n",
    "    ds = ds.map(lambda x,y: preprocess(x,y,aug), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_ds(train_paths, train_labels, True)\n",
    "val_ds   = make_ds(val_paths, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1061136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== BUILD MODEL (FULL FINE-TUNING) ====================\n",
    "print(\"\\nLoading YAMNet as tf.Module...\")\n",
    "\n",
    "yamnet_layer = hub.KerasLayer(YAMNET_HANDLE, trainable=True)\n",
    "\n",
    "class FineTunedYAMNet(tf.keras.Model):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.yamnet = yamnet_layer\n",
    "        self.pool = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        self.head = tf.keras.layers.Dense(n_classes, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        # x shape: [B, FRAME_LENGTH]\n",
    "        # Map each example in the batch to YAMNet, which expects 1D waveform\n",
    "        def per_example(wav):\n",
    "            scores, embeddings, _ = self.yamnet(wav)  # wav: [samples]\n",
    "            return embeddings  # [T, 1024]\n",
    "\n",
    "        # Apply YAMNet to each waveform in the batch\n",
    "        embeddings = tf.map_fn(per_example, x, dtype=tf.float32, parallel_iterations=4)\n",
    "        # embeddings shape: [B, T, 1024]\n",
    "        pooled = self.pool(embeddings)  # [B, 1024]\n",
    "        return self.head(pooled)  # [B, num_classes]\n",
    "\n",
    "model = FineTunedYAMNet(len(label_to_id))\n",
    "_ = model(tf.random.normal([1, FRAME_LENGTH]))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de976a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== TRAINING ==================\n",
    "class MacroF1(tf.keras.metrics.Metric):\n",
    "    def __init__(self, n_classes, name=\"macro_f1\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.f1 = self.add_weight(name=\"f1\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        y_true_oh = tf.one_hot(y_true, depth=self.n_classes)\n",
    "        y_pred_oh = tf.one_hot(y_pred, depth=self.n_classes)\n",
    "\n",
    "        tp = tf.reduce_sum(y_true_oh * y_pred_oh, axis=0)\n",
    "        fp = tf.reduce_sum((1 - y_true_oh) * y_pred_oh, axis=0)\n",
    "        fn = tf.reduce_sum(y_true_oh * (1 - y_pred_oh), axis=0)\n",
    "\n",
    "        precision = tp / (tp + fp + 1e-8)\n",
    "        recall = tp / (tp + fn + 1e-8)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "        batch_f1 = tf.reduce_mean(f1)\n",
    "\n",
    "        self.f1.assign_add(batch_f1)\n",
    "        self.count.assign_add(1.0)\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1 / (self.count + 1e-8)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.f1.assign(0.0)\n",
    "        self.count.assign(0.0)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(LEARNING_RATE, weight_decay=1e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy', MacroF1(len(label_to_id))]\n",
    ")\n",
    "\n",
    "\n",
    "cb=[\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_macro_f1',patience=PATIENCE_EARLY,mode='max',restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_macro_f1',factor=0.5,patience=PATIENCE_LR,mode='max'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(os.path.join(MODELS_DIR,'best.keras'),monitor='val_macro_f1',mode='max',save_best_only=True),\n",
    "    tf.keras.callbacks.CSVLogger(os.path.join(RESULTS_DIR,'train_log.csv'))\n",
    "]\n",
    "\n",
    "history=model.fit(train_ds,validation_data=val_ds,epochs=EPOCHS,callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1da610",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true,y_pred=[],[]\n",
    "for x,y in test_ds:\n",
    "    p=model.predict(x,verbose=0)\n",
    "    y_true.extend(y.numpy()); y_pred.extend(np.argmax(p,1))\n",
    "val_f1=f1_score(y_true,y_pred,average='macro')\n",
    "print(classification_report(y_true,y_pred,target_names=[id_to_label[i] for i in range(len(id_to_label))]))\n",
    "print(\"Test Macro-F1:\",val_f1)\n",
    "\n",
    "# ================== SAVE MODEL ==================\n",
    "model.save(os.path.join(MODELS_DIR,'yamnet_finetuned_final.keras'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
