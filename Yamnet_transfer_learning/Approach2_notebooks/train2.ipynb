{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bad900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress TF warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Configuration\n",
    "PROCESSED_ROOT = '../data/processed'\n",
    "MODEL_DIR = '../models/fine_tuned_yamnet'\n",
    "YAMNET_MODEL_HANDLE = 'https://tfhub.dev/google/yamnet/1'\n",
    "TARGET_SR = 16000\n",
    "BATCH_SIZE = 16  # Start with 16, increase if GPU allows\n",
    "RANDOM_SEED = 42\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Load YAMNet and modify architecture\n",
    "print(\"\\nLoading YAMNet model from TensorFlow Hub...\")\n",
    "yamnet_model = hub.load(YAMNET_MODEL_HANDLE)\n",
    "print(\"YAMNet model loaded successfully\")\n",
    "\n",
    "# Access penultimate layer (embeddings)\n",
    "inputs = tf.keras.layers.Input(shape=(None,), dtype=tf.float32, name='input')  # Raw waveform input\n",
    "_, embeddings, _ = yamnet_model(inputs)  # Get embeddings\n",
    "\n",
    "# Add new head for 5 classes\n",
    "output = tf.keras.layers.Dense(5, activation='softmax', name='predictions')(embeddings)\n",
    "\n",
    "# Create full model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "model.trainable = True  # Unfreeze all layers\n",
    "\n",
    "# Compile model\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Load metadata for splits\n",
    "train_meta = pd.read_csv(os.path.join(PROCESSED_ROOT, 'train/train_metadata.csv'))\n",
    "val_meta = pd.read_csv(os.path.join(PROCESSED_ROOT, 'val/val_metadata.csv'))\n",
    "test_meta = pd.read_csv(os.path.join(PROCESSED_ROOT, 'test/test_metadata.csv'))\n",
    "\n",
    "# Create label encoding (assuming balanced, no class weights)\n",
    "categories = sorted(train_meta['category'].unique())\n",
    "category_to_id = {cat: idx for idx, cat in enumerate(categories)}\n",
    "train_meta['label'] = train_meta['category'].map(category_to_id)\n",
    "val_meta['label'] = val_meta['category'].map(category_to_id)\n",
    "test_meta['label'] = test_meta['category'].map(category_to_id)\n",
    "\n",
    "# TF Dataset generator\n",
    "def load_frame(path, label):\n",
    "    frame = np.load(path.numpy().decode('utf-8')).astype(np.float32)\n",
    "    return frame, label\n",
    "\n",
    "def make_dataset(meta_df, batch_size=BATCH_SIZE):\n",
    "    paths = meta_df['frame_path'].values\n",
    "    labels = meta_df['label'].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    dataset = dataset.map(lambda p, l: tf.py_function(load_frame, [p, l], [tf.float32, tf.int64]),\n",
    "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_ds = make_dataset(train_meta)\n",
    "val_ds = make_dataset(val_meta)\n",
    "test_ds = make_dataset(test_meta)\n",
    "\n",
    "# Augmentation in pipeline \n",
    "def augment(frame, label):\n",
    "    noise = tf.random.normal(tf.shape(frame), dtype=tf.float32) * 0.005\n",
    "    frame += noise\n",
    "    return frame, label\n",
    "\n",
    "train_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)  # Apply to train only\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint(os.path.join(MODEL_DIR, 'best_model.h5'), save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Evaluate on test\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Custom metrics\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for frames, labels in test_ds:\n",
    "    preds = model.predict(frames)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(f\"F1 (macro): {f1:.4f}\")\n",
    "print(f\"Precision (macro): {precision:.4f}\")\n",
    "print(f\"Recall (macro): {recall:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'confusion_matrix.png'))\n",
    "\n",
    "# Optimization for mobile (TFLite)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, 'yamnet_fine_tuned.tflite'), 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Test latency (example on sample)\n",
    "interpreter = tf.lite.Interpreter(model_path=os.path.join(MODEL_DIR, 'yamnet_fine_tuned.tflite'))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Sample inference\n",
    "sample_frame = np.load(test_meta['frame_path'].iloc[0]).astype(np.float32)[np.newaxis, :]\n",
    "import time\n",
    "start = time.time()\n",
    "interpreter.set_tensor(input_details[0]['index'], sample_frame)\n",
    "interpreter.invoke()\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n",
    "latency = time.time() - start\n",
    "print(f\"Inference latency: {latency:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
