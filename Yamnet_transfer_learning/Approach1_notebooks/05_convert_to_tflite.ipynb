{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d457a3",
   "metadata": {},
   "source": [
    "Convert the best Keras model → TFLite\n",
    "with a **true “none”** output when no target sound is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a54db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ----------------------------------------------------------------------\n",
    "MODELS_DIR       = '../models/models_approach1'\n",
    "RESULTS_DIR      = '../results/results_approach1'\n",
    "SAVED_MODELS_DIR = os.path.join(MODELS_DIR, 'saved_models')\n",
    "TFLITE_DIR       = '../models/tflite_models'\n",
    "TEST_RAW_DIR     = '../data/split_processed/test'\n",
    "\n",
    "# ---- thresholds (tune once) ----\n",
    "CONFIDENCE_THRESHOLD       = 0.85   # must be >= this to even consider a class\n",
    "MIN_CONSECUTIVE_DETECTIONS = 7\n",
    "RMS_THRESHOLD              = 0.03   # silence gate\n",
    "OVERCONFIDENCE_CAP         = 0.98   # reject > 0.98 (model hallucination)\n",
    "RESET_AFTER_SECONDS        = 5.0\n",
    "\n",
    "os.makedirs(TFLITE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c404ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM YAMNET LAYER (required for load_model)\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class YamnetEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, yamnet_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.yamnet_model = yamnet_model\n",
    "    def call(self, inputs):\n",
    "        def _single(w):\n",
    "            _, emb, _ = self.yamnet_model(w)\n",
    "            return tf.reduce_mean(emb, axis=0)\n",
    "        return tf.map_fn(_single, inputs, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e99412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LOAD BEST MODEL\n",
    "print(\"1. LOADING BEST KERAS MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "leaderboard_path = os.path.join(RESULTS_DIR, 'final_test_leaderboard.csv')\n",
    "df = pd.read_csv(leaderboard_path)\n",
    "best_name = df.iloc[0]['Model']\n",
    "best_f1   = df.iloc[0]['F1_Macro']\n",
    "print(f\"Best model: {best_name} (F1-macro = {best_f1:.4f})\")\n",
    "\n",
    "model_path = os.path.join(SAVED_MODELS_DIR, f\"{best_name.lower()}_full\")\n",
    "model = tf.keras.models.load_model(\n",
    "    model_path,\n",
    "    custom_objects={'YamnetEmbedding': YamnetEmbedding}\n",
    ")\n",
    "print(\"Keras model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56310a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. FREEZE → PLAIN SavedModel (removes hub URL)\n",
    "print(\"2. FREEZING TO SAVEDMODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "input_spec = tf.TensorSpec([1, 15360], tf.float32)\n",
    "concrete   = tf.function(lambda x: model(x)).get_concrete_function(input_spec)\n",
    "frozen_dir = os.path.join(TFLITE_DIR, \"frozen_savedmodel\")\n",
    "tf.saved_model.save(model, frozen_dir, signatures=concrete)\n",
    "print(f\"Frozen SavedModel → {frozen_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. CONVERT TO TFLITE\n",
    "print(\"3. CONVERTING TO TFLITE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(frozen_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "print(\"Running conversion …\")\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_path = os.path.join(TFLITE_DIR, f\"{best_name.lower()}_model.tflite\")\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "size_mb = len(tflite_model) / (1024*1024)\n",
    "print(f\"TFLite model saved → {tflite_path} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. METADATA\n",
    "print(\"4. WRITING METADATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "label_encoder = joblib.load(os.path.join(MODELS_DIR, 'label_encoder.pkl'))\n",
    "classes = label_encoder.classes_\n",
    "\n",
    "metadata = {\n",
    "    \"model_name\": best_name,\n",
    "    \"test_f1_score\": float(best_f1),\n",
    "    \"classes\": classes.tolist(),\n",
    "    \"sample_rate\": 16000,\n",
    "    \"input_length\": 15360,\n",
    "    \"duration_seconds\": 0.96,\n",
    "    \"confidence_threshold\": CONFIDENCE_THRESHOLD,\n",
    "    \"min_consecutive_detections\": MIN_CONSECUTIVE_DETECTIONS,\n",
    "    \"rms_threshold\": RMS_THRESHOLD,\n",
    "    \"overconfidence_cap\": OVERCONFIDENCE_CAP,\n",
    "    \"reset_after_seconds\": RESET_AFTER_SECONDS,\n",
    "    \"input_shape\": [1, 15360],\n",
    "    \"output_shape\": [1, len(classes)],\n",
    "    \"description\": \"5-class detector – returns None when no target sound is present\"\n",
    "}\n",
    "metadata_path = os.path.join(TFLITE_DIR, \"model_metadata.json\")\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"Metadata → {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc6f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. QUICK SANITY CHECK\n",
    "print(\"5. QUICK TFLITE TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "interp = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interp.allocate_tensors()\n",
    "inp = interp.get_input_details()[0]\n",
    "out = interp.get_output_details()[0]\n",
    "\n",
    "rand = np.random.randn(15360).astype(np.float32)\n",
    "interp.set_tensor(inp['index'], rand[np.newaxis,:])\n",
    "interp.invoke()\n",
    "probs = interp.get_tensor(out['index'])[0]\n",
    "print(f\"Random → {classes[np.argmax(probs)]} (conf {probs.max():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbcca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. DETECTION LOGIC (returns None for “none”)\n",
    "class Detector:\n",
    "    def __init__(self):\n",
    "        self.interp = tf.lite.Interpreter(model_path=tflite_path)\n",
    "        self.interp.allocate_tensors()\n",
    "        self.in_idx = self.interp.get_input_details()[0]['index']\n",
    "        self.out_idx = self.interp.get_output_details()[0]['index']\n",
    "        self.buffer = deque(maxlen=MIN_CONSECUTIVE_DETECTIONS)\n",
    "        self.last_trigger = None\n",
    "\n",
    "    def _infer(self, audio: np.ndarray) -> np.ndarray:\n",
    "        self.interp.set_tensor(self.in_idx, audio[np.newaxis,:])\n",
    "        self.interp.invoke()\n",
    "        return self.interp.get_tensor(self.out_idx)[0]\n",
    "\n",
    "    def detect(self, audio: np.ndarray):\n",
    "        \"\"\"Return dict with 'class' == None when no target sound.\"\"\"\n",
    "        rms = np.sqrt(np.mean(audio**2))\n",
    "        if rms < RMS_THRESHOLD:                     # ---- silence ----\n",
    "            self.buffer.clear()\n",
    "            self.last_trigger = None\n",
    "            return {\"class\": None, \"confidence\": 0.0, \"triggered\": False,\n",
    "                    \"reason\": \"silence\", \"rms\": rms}\n",
    "\n",
    "        probs = self._infer(audio)\n",
    "        idx   = int(np.argmax(probs))\n",
    "        conf  = float(probs[idx])\n",
    "        cls   = classes[idx]\n",
    "\n",
    "        # ---- over-confident hallucination ----\n",
    "        if conf > OVERCONFIDENCE_CAP:\n",
    "            self.buffer.clear()\n",
    "            return {\"class\": None, \"confidence\": conf, \"triggered\": False,\n",
    "                    \"reason\": \"overconfident\"}\n",
    "\n",
    "        # ---- not confident enough for *any* class ----\n",
    "        if conf < CONFIDENCE_THRESHOLD:\n",
    "            self.buffer.clear()\n",
    "            return {\"class\": None, \"confidence\": conf, \"triggered\": False,\n",
    "                    \"reason\": \"low_confidence\"}\n",
    "\n",
    "        # ---- we have a plausible candidate ----\n",
    "        self.buffer.append(cls)\n",
    "\n",
    "        triggered = (len(self.buffer) >= MIN_CONSECUTIVE_DETECTIONS and\n",
    "                     len(set(self.buffer)) == 1)\n",
    "\n",
    "        now = time.time()\n",
    "        if triggered:\n",
    "            self.last_trigger = now\n",
    "        elif self.last_trigger and now - self.last_trigger > RESET_AFTER_SECONDS:\n",
    "            self.buffer.clear()\n",
    "\n",
    "        return {\n",
    "            \"class\": cls if triggered else None,\n",
    "            \"confidence\": conf,\n",
    "            \"triggered\": triggered,\n",
    "            \"buffer_len\": len(self.buffer),\n",
    "            \"rms\": rms\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a991041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. BACKGROUND TEST (must stay at 0 %)\n",
    "print(\"7. BACKGROUND TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "bg_dir = Path(TEST_RAW_DIR) / \"background\"\n",
    "if not bg_dir.exists():\n",
    "    bg_dir.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(bg_dir / \"silence.npy\", np.zeros(15360, dtype=np.float32))\n",
    "    np.save(bg_dir / \"noise.npy\", np.random.randn(15360).astype(np.float32)*0.05)\n",
    "\n",
    "det = Detector()\n",
    "bg_res = []\n",
    "for npy in list(bg_dir.glob(\"*.npy\"))[:10]:\n",
    "    a = np.load(npy).astype(np.float32)\n",
    "    if a.shape == (15360,):\n",
    "        bg_res.append(det.detect(a))\n",
    "\n",
    "rate = sum(1 for r in bg_res if r[\"triggered\"]) / len(bg_res) if bg_res else 0\n",
    "print(f\"Trigger rate on background: {rate:.2%}\")\n",
    "assert rate == 0.0, \"Background must never trigger!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. GENERATE PYTHON WRAPPER (audio_detector.py)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"8. WRITING INFERENCE WRAPPER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "wrapper_code = f'''\\\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "class AudioEventDetector:\n",
    "    \"\"\"\n",
    "    Robust 5-class detector.\n",
    "    Returns **None** when none of the target sounds is present.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model_path=\"{tflite_path}\",\n",
    "                 metadata_path=\"{metadata_path}\",\n",
    "                 rms_threshold={RMS_THRESHOLD},\n",
    "                 confidence_threshold={CONFIDENCE_THRESHOLD},\n",
    "                 min_consecutive={MIN_CONSECUTIVE_DETECTIONS},\n",
    "                 overconfidence_cap={OVERCONFIDENCE_CAP},\n",
    "                 reset_after_seconds={RESET_AFTER_SECONDS}):\n",
    "\n",
    "        self.interp = tf.lite.Interpreter(model_path=model_path)\n",
    "        self.interp.allocate_tensors()\n",
    "        self.in_idx = self.interp.get_input_details()[0][\"index\"]\n",
    "        self.out_idx = self.interp.get_output_details()[0][\"index\"]\n",
    "\n",
    "        with open(metadata_path) as f:\n",
    "            meta = json.load(f)\n",
    "        self.classes = meta[\"classes\"]\n",
    "\n",
    "        self.rms_thr = rms_threshold\n",
    "        self.conf_thr = confidence_threshold\n",
    "        self.min_cons = min_consecutive\n",
    "        self.over_cap = overconfidence_cap\n",
    "        self.reset_sec = reset_after_seconds\n",
    "\n",
    "        self.buffer = deque(maxlen=self.min_cons)\n",
    "        self.last_trigger = None\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    def _infer(self, audio: np.ndarray) -> np.ndarray:\n",
    "        if audio.shape != (15360,):\n",
    "            raise ValueError(\"Audio must be exactly 15360 samples\")\n",
    "        inp = audio.astype(np.float32)[np.newaxis,:]\n",
    "        self.interp.set_tensor(self.in_idx, inp)\n",
    "        self.interp.invoke()\n",
    "        return self.interp.get_tensor(self.out_idx)[0]\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    def detect(self, audio: np.ndarray):\n",
    "        rms = np.sqrt(np.mean(audio**2))\n",
    "\n",
    "        # ---- silence ----\n",
    "        if rms < self.rms_thr:\n",
    "            self.buffer.clear()\n",
    "            self.last_trigger = None\n",
    "            return {{\"class\": None, \"confidence\": 0.0, \"triggered\": False,\n",
    "                    \"reason\": \"silence\", \"probabilities\": [0.0]*len(self.classes)}}\n",
    "\n",
    "        probs = self._infer(audio)\n",
    "        idx = int(np.argmax(probs))\n",
    "        conf = float(probs[idx])\n",
    "        cls = self.classes[idx]\n",
    "\n",
    "        # ---- over-confident hallucination ----\n",
    "        if conf > self.over_cap:\n",
    "            self.buffer.clear()\n",
    "            return {{\"class\": None, \"confidence\": conf, \"triggered\": False,\n",
    "                    \"reason\": \"overconfident\", \"probabilities\": probs.tolist()}}\n",
    "\n",
    "        # ---- not confident enough for any class ----\n",
    "        if conf < self.conf_thr:\n",
    "            self.buffer.clear()\n",
    "            return {{\"class\": None, \"confidence\": conf, \"triggered\": False,\n",
    "                    \"reason\": \"low_confidence\", \"probabilities\": probs.tolist()}}\n",
    "\n",
    "        # ---- plausible candidate ----\n",
    "        self.buffer.append(cls)\n",
    "\n",
    "        triggered = (len(self.buffer) >= self.min_cons and\n",
    "                     len(set(self.buffer)) == 1)\n",
    "\n",
    "        now = time.time()\n",
    "        if triggered:\n",
    "            self.last_trigger = now\n",
    "        elif self.last_trigger and now - self.last_trigger > self.reset_sec:\n",
    "            self.buffer.clear()\n",
    "\n",
    "        return {{\n",
    "            \"class\": cls if triggered else None,\n",
    "            \"confidence\": conf,\n",
    "            \"triggered\": triggered,\n",
    "            \"probabilities\": probs.tolist()\n",
    "        }}\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    def reset(self):\n",
    "        self.buffer.clear()\n",
    "        self.last_trigger = None\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Demo\n",
    "# ------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    d = AudioEventDetector()\n",
    "    def demo(name, gen):\n",
    "        print(f\"\\\\n--- {{name}} ---\")\n",
    "        for i in range(8):\n",
    "            r = d.detect(gen())\n",
    "            cls = r[\"class\"] if r[\"class\"] else \"None\"\n",
    "            print(f\"{{i:02d}}: {{cls:<12}} conf={{r['confidence']:.4f}} trigger={{r['triggered']}}\")\n",
    "    demo(\"SILENCE\", lambda: np.zeros(15360, dtype=np.float32))\n",
    "    demo(\"LOW NOISE\", lambda: np.random.uniform(-0.05,0.05,15360).astype(np.float32))\n",
    "    demo(\"WHITE NOISE\", lambda: np.random.randn(15360).astype(np.float32)*0.15)\n",
    "'''\n",
    "\n",
    "wrapper_path = os.path.join(TFLITE_DIR, \"audio_detector.py\")\n",
    "with open(wrapper_path, 'w') as f:\n",
    "    f.write(wrapper_code)\n",
    "print(f\"Wrapper written → {wrapper_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL SUMMARY\n",
    "print(\"CONVERSION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"TFLite model : {tflite_path} ({size_mb:.2f} MB)\")\n",
    "print(f\"Metadata     : {metadata_path}\")\n",
    "print(f\"Wrapper      : {wrapper_path}\")\n",
    "print(\"\\nRun the demo:\")\n",
    "print(f\"    python {wrapper_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
