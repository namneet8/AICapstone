{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d457a3",
   "metadata": {},
   "source": [
    "Convert the best Keras model → TFLite\n",
    "with a **true “none”** output when no target sound is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a54db07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\301364822\\AppData\\Local\\miniconda3\\envs\\AI-Capstone-FINAL\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\301364822\\AppData\\Local\\miniconda3\\envs\\AI-Capstone-FINAL\\Lib\\site-packages\\tensorflow_hub\\__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\301364822\\AppData\\Local\\miniconda3\\envs\\AI-Capstone-FINAL\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\301364822\\AppData\\Local\\miniconda3\\envs\\AI-Capstone-FINAL\\Lib\\site-packages\\tensorflow_hub\\native_module.py:92: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\301364822\\AppData\\Local\\miniconda3\\envs\\AI-Capstone-FINAL\\Lib\\site-packages\\tensorflow_hub\\saved_model_module.py:40: The name tf.saved_model.constants.LEGACY_INIT_OP_KEY is deprecated. Please use tf.compat.v1.saved_model.constants.LEGACY_INIT_OP_KEY instead.\n",
      "\n",
      "Environment set up and Custom Layers defined.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# ==================== PATHS ====================\n",
    "MODELS_DIR       = '../models/models_approach1'\n",
    "RESULTS_DIR      = '../results/results_approach1'\n",
    "SAVED_MODELS_DIR = os.path.join(MODELS_DIR, 'saved_models')\n",
    "TFLITE_DIR       = '../models/tflite_models'\n",
    "\n",
    "os.makedirs(TFLITE_DIR, exist_ok=True)\n",
    "\n",
    "# ==================== CUSTOM LAYERS (REQUIRED FOR LOADING) ====================\n",
    "# These must match exactly what was used to save the model\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class YamnetEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, yamnet_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.yamnet_model = yamnet_model\n",
    "\n",
    "    def call(self, inputs):\n",
    "        def map_fn(wave):\n",
    "            scores, embeddings, _ = self.yamnet_model(wave)\n",
    "            return tf.reduce_mean(embeddings, axis=0)\n",
    "        return tf.map_fn(map_fn, inputs, dtype=tf.float32)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class ScalerLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, mean=None, scale=None, **kwargs):\n",
    "        super(ScalerLayer, self).__init__(**kwargs)\n",
    "        if mean is not None:\n",
    "            self.mean_weight = tf.Variable(initial_value=mean, trainable=False, dtype=tf.float32)\n",
    "        if scale is not None:\n",
    "            self.scale_weight = tf.Variable(initial_value=scale, trainable=False, dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.mean_weight) / self.scale_weight\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(ScalerLayer, self).get_config()\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class TemperatureSoftmax(tf.keras.layers.Layer):\n",
    "    def __init__(self, temperature=1.0, **kwargs):\n",
    "        super(TemperatureSoftmax, self).__init__(**kwargs)\n",
    "        self.temperature = float(temperature)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.softmax(inputs / self.temperature)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(TemperatureSoftmax, self).get_config()\n",
    "        config.update({\"temperature\": self.temperature})\n",
    "        return config\n",
    "\n",
    "print(\"Environment set up and Custom Layers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c404ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading SavedModel from: ../models/models_approach1\\saved_models\\custom_keras_nn_full\n",
      "WARNING:tensorflow:From c:\\Users\\301364822\\AppData\\Local\\miniconda3\\envs\\AI-Capstone-FINAL\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\301364822\\AppData\\Local\\miniconda3\\envs\\AI-Capstone-FINAL\\Lib\\site-packages\\keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\301364822\\AppData\\Local\\miniconda3\\envs\\AI-Capstone-FINAL\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "  Model loaded successfully. Starting conversion...\n",
      "  Converting (Float32)...\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\301364~1\\AppData\\Local\\Temp\\tmp88bug_mb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\301364~1\\AppData\\Local\\Temp\\tmp88bug_mb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: ../models/tflite_models\\Custom_Keras_NN_float32.tflite (13.36 MB)\n",
      "  Converting (Dynamic Range Quantization)...\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\301364~1\\AppData\\Local\\Temp\\tmpj9dkt6pc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\301364~1\\AppData\\Local\\Temp\\tmpj9dkt6pc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: ../models/tflite_models\\Custom_Keras_NN_quant.tflite (3.54 MB)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_tflite(model_name):\n",
    "    # 1. Construct path to the SavedModel directory\n",
    "    # (Matches how we saved it: 'custom_keras_nn_full')\n",
    "    saved_model_path = os.path.join(SAVED_MODELS_DIR, f'{model_name.lower()}_full')\n",
    "    \n",
    "    print(f\"\\nLoading SavedModel from: {saved_model_path}\")\n",
    "    \n",
    "    # Load the model to ensure it works\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(\n",
    "            saved_model_path,\n",
    "            custom_objects={\n",
    "                'YamnetEmbedding': YamnetEmbedding,\n",
    "                'ScalerLayer': ScalerLayer,\n",
    "                'TemperatureSoftmax': TemperatureSoftmax\n",
    "            }\n",
    "        )\n",
    "        print(\"  Model loaded successfully. Starting conversion...\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    # ==================== CONVERTER SETUP ====================\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    \n",
    "    # CRITICAL: Allow TensorFlow Ops (Flex Delegate)\n",
    "    # YAMNet uses audio signal processing ops (STFT) that are not in standard TFLite.\n",
    "    converter.target_spec.supported_ops = [\n",
    "        tf.lite.OpsSet.TFLITE_BUILTINS, # Standard TFLite ops\n",
    "        tf.lite.OpsSet.SELECT_TF_OPS    # Fallback to TF for complex audio ops\n",
    "    ]\n",
    "    \n",
    "    # Optimization 1: Standard Float32\n",
    "    print(\"  Converting (Float32)...\")\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    # Save Float32\n",
    "    float_path = os.path.join(TFLITE_DIR, f'{model_name}_float32.tflite')\n",
    "    with open(float_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f\"  Saved: {float_path} ({len(tflite_model)/1024/1024:.2f} MB)\")\n",
    "\n",
    "    # Optimization 2: Dynamic Range Quantization (OPTIONAL but Recommended)\n",
    "    # This reduces weights to int8, making the model 4x smaller\n",
    "    print(\"  Converting (Dynamic Range Quantization)...\")\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_quant_model = converter.convert()\n",
    "    \n",
    "    # Save Quantized\n",
    "    quant_path = os.path.join(TFLITE_DIR, f'{model_name}_quant.tflite')\n",
    "    with open(quant_path, 'wb') as f:\n",
    "        f.write(tflite_quant_model)\n",
    "    print(f\"  Saved: {quant_path} ({len(tflite_quant_model)/1024/1024:.2f} MB)\")\n",
    "\n",
    "# Run conversion for the winning model\n",
    "convert_to_tflite('Custom_Keras_NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e99412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying: ../models/tflite_models\\Custom_Keras_NN_float32.tflite\n",
      "  Success! Output shape: (1, 6)\n",
      "  Output Probabilities Sum: 1.0000\n",
      "\n",
      "Verifying: ../models/tflite_models\\Custom_Keras_NN_quant.tflite\n",
      "  Success! Output shape: (1, 6)\n",
      "  Output Probabilities Sum: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def verify_tflite(tflite_path):\n",
    "    print(f\"\\nVerifying: {tflite_path}\")\n",
    "    try:\n",
    "        # Load Interpreter\n",
    "        interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "        interpreter.allocate_tensors()\n",
    "\n",
    "        # Get details\n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "\n",
    "        # Create dummy input (15360 samples of audio)\n",
    "        input_shape = input_details[0]['shape']\n",
    "        # If shape is dynamic [1, 15360], numpy needs exact match\n",
    "        dummy_input = np.random.randn(*input_shape).astype(np.float32)\n",
    "\n",
    "        # Run Inference\n",
    "        interpreter.set_tensor(input_details[0]['index'], dummy_input)\n",
    "        interpreter.invoke()\n",
    "        \n",
    "        # Get Output\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        print(f\"  Success! Output shape: {output_data.shape}\")\n",
    "        print(f\"  Output Probabilities Sum: {np.sum(output_data):.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Verification Failed: {e}\")\n",
    "\n",
    "# Verify both models\n",
    "verify_tflite(os.path.join(TFLITE_DIR, 'Custom_Keras_NN_float32.tflite'))\n",
    "verify_tflite(os.path.join(TFLITE_DIR, 'Custom_Keras_NN_quant.tflite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85237e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PREPARING TEST DATA FOR TFLITE EVALUATION\n",
      "================================================================================\n",
      "Loading .npy files...\n",
      "Loaded 1460 samples for testing.\n",
      "\n",
      "Evaluating TFLite Model: Custom_Keras_NN_float32.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 1460/1460 [00:28<00:00, 50.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy:      0.8322\n",
      "  F1 Macro:      0.7162\n",
      "  Avg Latency:   19.69 ms/sample\n",
      "  Model Size:    13.36 MB\n",
      "\n",
      "Evaluating TFLite Model: Custom_Keras_NN_quant.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 1460/1460 [00:23<00:00, 60.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy:      0.0178\n",
      "  F1 Macro:      0.0250\n",
      "  Avg Latency:   16.42 ms/sample\n",
      "  Model Size:    3.54 MB\n",
      "\n",
      "============================================================\n",
      "TFLITE PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "                         Model  Accuracy       F1   Latency   Size_MB\n",
      "Custom_Keras_NN_float32.tflite  0.832192 0.716225 19.692324 13.362617\n",
      "  Custom_Keras_NN_quant.tflite  0.017808 0.024989 16.420441  3.535515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from glob import glob\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# ==================== 1. LOAD TEST DATA (RAW AUDIO) ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPARING TEST DATA FOR TFLITE EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load Label Encoder\n",
    "label_encoder = joblib.load(os.path.join(MODELS_DIR, 'label_encoder.pkl'))\n",
    "classes = label_encoder.classes_\n",
    "\n",
    "# Map folder names to class names\n",
    "category_mapping = {\n",
    "    'alarm_clock': 'Alarm_Clock',\n",
    "    'car_horn': 'Car_Horn',\n",
    "    'glass_breaking': 'Glass_Breaking',\n",
    "    'gunshot': 'Gunshot',\n",
    "    'siren': 'Siren'\n",
    "}\n",
    "\n",
    "raw_audio_list = []\n",
    "labels_list = []\n",
    "target_length = 15360  # 0.96s @ 16kHz\n",
    "\n",
    "print(\"Loading .npy files...\")\n",
    "for folder_name, class_name in category_mapping.items():\n",
    "    folder_path = os.path.join('../data/split_processed/test', folder_name) # Hardcoded path based on previous context\n",
    "    if not os.path.exists(folder_path): continue\n",
    "    \n",
    "    npy_files = glob(os.path.join(folder_path, '*.npy'))\n",
    "    for npy_file in npy_files:\n",
    "        try:\n",
    "            audio = np.load(npy_file)\n",
    "            if audio.ndim > 1: audio = audio.flatten()\n",
    "            if len(audio) == target_length:\n",
    "                raw_audio_list.append(audio)\n",
    "                labels_list.append(class_name)\n",
    "        except: pass\n",
    "\n",
    "X_test_tflite = np.array(raw_audio_list, dtype=np.float32)\n",
    "y_test_labels = np.array(labels_list)\n",
    "y_test_encoded = label_encoder.transform(y_test_labels)\n",
    "\n",
    "print(f\"Loaded {len(X_test_tflite)} samples for testing.\")\n",
    "\n",
    "# ==================== 2. TFLITE INFERENCE FUNCTION ====================\n",
    "def evaluate_tflite(model_path, X_data, y_true):\n",
    "    print(f\"\\nEvaluating TFLite Model: {os.path.basename(model_path)}\")\n",
    "    \n",
    "    # Load Interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    input_index = input_details[0]['index']\n",
    "    output_index = output_details[0]['index']\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # TFLite usually handles one sample at a time in Python\n",
    "    # (Unless resized, but loop is safer for verification)\n",
    "    for i in tqdm(range(len(X_data)), desc=\"Running Inference\"):\n",
    "        # Get sample and ensure shape is (1, 15360)\n",
    "        sample = X_data[i].reshape(1, -1)\n",
    "        \n",
    "        interpreter.set_tensor(input_index, sample)\n",
    "        interpreter.invoke()\n",
    "        \n",
    "        output = interpreter.get_tensor(output_index)\n",
    "        pred_label = np.argmax(output)\n",
    "        predictions.append(pred_label)\n",
    "\n",
    "    total_time = (time.time() - start_time) * 1000 # to ms\n",
    "    avg_latency = total_time / len(X_data)\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_true, predictions)\n",
    "    f1 = f1_score(y_true, predictions, average='macro')\n",
    "    model_size = os.path.getsize(model_path) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"  Accuracy:      {acc:.4f}\")\n",
    "    print(f\"  F1 Macro:      {f1:.4f}\")\n",
    "    print(f\"  Avg Latency:   {avg_latency:.2f} ms/sample\")\n",
    "    print(f\"  Model Size:    {model_size:.2f} MB\")\n",
    "    \n",
    "    return {\n",
    "        'Model': os.path.basename(model_path),\n",
    "        'Accuracy': acc,\n",
    "        'F1': f1,\n",
    "        'Latency': avg_latency,\n",
    "        'Size_MB': model_size\n",
    "    }\n",
    "\n",
    "# ==================== 3. RUN EVALUATION ====================\n",
    "tflite_results = []\n",
    "\n",
    "# 1. Test Float32 Model\n",
    "float_model_path = os.path.join(TFLITE_DIR, 'Custom_Keras_NN_float32.tflite')\n",
    "if os.path.exists(float_model_path):\n",
    "    res = evaluate_tflite(float_model_path, X_test_tflite, y_test_encoded)\n",
    "    tflite_results.append(res)\n",
    "\n",
    "# 2. Test Quantized Model\n",
    "quant_model_path = os.path.join(TFLITE_DIR, 'Custom_Keras_NN_quant.tflite')\n",
    "if os.path.exists(quant_model_path):\n",
    "    res = evaluate_tflite(quant_model_path, X_test_tflite, y_test_encoded)\n",
    "    tflite_results.append(res)\n",
    "\n",
    "# ==================== 4. SUMMARY TABLE ====================\n",
    "if tflite_results:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TFLITE PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    df_res = pd.DataFrame(tflite_results)\n",
    "    print(df_res[['Model', 'Accuracy', 'F1', 'Latency', 'Size_MB']].to_string(index=False))\n",
    "    \n",
    "    # Optional: Save results\n",
    "    df_res.to_csv(os.path.join(RESULTS_DIR, 'tflite_evaluation_results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbd96a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Capstone-FINAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
