{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "673581fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.effects\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eefa1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/raw'\n",
    "EXPLORATION_CSV = 'audio_data_exploration.csv'\n",
    "PROCESSED_ROOT = '../data/processed'\n",
    "\n",
    "# Audio parameters\n",
    "TARGET_SR = 16000\n",
    "FRAME_SEC = 0.96\n",
    "HOP_SEC = 0.48\n",
    "\n",
    "# aggressive silence threshold based on post-processing analysis\n",
    "SILENCE_RMS_THR = 0.015  # to filter out low-quality frames\n",
    "CLIP_MAX_AMP_THR = 0.98\n",
    "\n",
    "# Quality thresholds to filter poor frames\n",
    "MIN_FRAME_RMS = 0.01  # Minimum RMS after normalization\n",
    "\n",
    "CATEGORY_RMS_TARGETS = {\n",
    "    'Glass_Breaking': 0.10, \n",
    "    'Alarm_Clock': 0.14,    \n",
    "    'Car_Horn': 0.17,       \n",
    "    'Gunshot': 0.16,       \n",
    "    'Siren': 0.19          \n",
    "}\n",
    "\n",
    "# augmentation to balance dataset\n",
    "AUGMENT_MULTIPLIERS = {\n",
    "    'Glass_Breaking': 4, \n",
    "    'Alarm_Clock': 3,   \n",
    "    'Siren': 2,          \n",
    "    'Car_Horn': 2,      \n",
    "    'Gunshot': 2         \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99ef9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5_hash(filepath: str) -> str:\n",
    "    \"\"\"Compute MD5 hash of a file.\"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "\n",
    "def load_audio(filepath: str):\n",
    "    \"\"\"Load audio, force mono and target sample rate.\"\"\"\n",
    "    y, sr = librosa.load(filepath, sr=TARGET_SR, mono=True)\n",
    "    return y, sr\n",
    "\n",
    "\n",
    "def compute_rms(y: np.ndarray) -> float:\n",
    "    \"\"\"Compute RMS energy.\"\"\"\n",
    "    return np.sqrt(np.mean(y**2))\n",
    "\n",
    "\n",
    "def estimate_snr(y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Estimate SNR using RMS-based method.\n",
    "    Returns SNR in dB.\n",
    "    NOTE: Not used in current pipeline - SNR filtering removed as it was\n",
    "    too aggressive and filtered out valid clean audio.\n",
    "    \"\"\"\n",
    "    rms_frames = librosa.feature.rms(y=y)[0]\n",
    "    signal_rms = np.mean(rms_frames)\n",
    "    noise_rms = np.min(rms_frames) + 1e-6\n",
    "    snr_db = 20 * np.log10(signal_rms / noise_rms) if signal_rms > 0 else 0\n",
    "    return snr_db\n",
    "\n",
    "\n",
    "def is_silent(y: np.ndarray, thr: float = SILENCE_RMS_THR) -> bool:\n",
    "    \"\"\"Return True if RMS is below the silence threshold.\"\"\"\n",
    "    return compute_rms(y) < thr\n",
    "\n",
    "\n",
    "def handle_clipping(y: np.ndarray, thr: float = CLIP_MAX_AMP_THR) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Scale down if max amplitude exceeds threshold.\n",
    "    \"\"\"\n",
    "    max_amp = np.max(np.abs(y))\n",
    "    if max_amp >= thr:\n",
    "        y = y / (max_amp + 1e-8) * 0.95\n",
    "    return np.clip(y, -1.0, 1.0)\n",
    "\n",
    "\n",
    "def normalise_rms(y: np.ndarray, target: float, max_gain: float = 5.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Scale to a target RMS energy level with maximum gain limit.\n",
    "    \"\"\"\n",
    "    current_rms = compute_rms(y)\n",
    "    if current_rms > 1e-8:\n",
    "        scale_factor = target / current_rms\n",
    "        scale_factor = min(scale_factor, max_gain)\n",
    "        y = y * scale_factor\n",
    "    return y\n",
    "\n",
    "\n",
    "def pad_to_length(y: np.ndarray, sr: int, target_sec: float = FRAME_SEC) -> np.ndarray:\n",
    "    \"\"\"Zero-pad if shorter than target length.\"\"\"\n",
    "    target_samples = int(target_sec * sr)\n",
    "    if len(y) < target_samples:\n",
    "        y = np.pad(y, (0, target_samples - len(y)), mode='constant')\n",
    "    return y\n",
    "\n",
    "\n",
    "def extract_frames(y: np.ndarray, sr: int,\n",
    "                   frame_sec: float = FRAME_SEC,\n",
    "                   hop_sec: float = HOP_SEC) -> list:\n",
    "    \"\"\"Extract overlapping frames from audio.\"\"\"\n",
    "    frame_samples = int(frame_sec * sr)\n",
    "    hop_samples = int(hop_sec * sr)\n",
    "    frames = []\n",
    "    \n",
    "    for start in range(0, len(y) - frame_samples + 1, hop_samples):\n",
    "        frame = y[start:start + frame_samples]\n",
    "        frames.append(frame)\n",
    "    \n",
    "    # Handle last frame if necessary\n",
    "    if len(y) > frame_samples and (len(y) - frame_samples) % hop_samples != 0:\n",
    "        last_frame = y[-frame_samples:]\n",
    "        frames.append(last_frame)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "\n",
    "def augment_frame(frame: np.ndarray, sr: int, category: str, \n",
    "                  n_augmentations: int) -> list:\n",
    "    \"\"\"\n",
    "    Generate augmented versions of a frame.\n",
    "    More consistent RMS preservation with tighter tolerance.\n",
    "    \"\"\"\n",
    "    augmented = [frame.copy()]\n",
    "    \n",
    "    if n_augmentations <= 1:\n",
    "        return augmented\n",
    "    \n",
    "    original_rms = compute_rms(frame)\n",
    "    \n",
    "    for i in range(n_augmentations - 1):\n",
    "        aug = frame.copy()\n",
    "        \n",
    "        # Time shift with zero padding (not circular)\n",
    "        shift_samples = np.random.randint(-len(aug)//8, len(aug)//8)\n",
    "        if shift_samples > 0:\n",
    "            aug = np.pad(aug[shift_samples:], (0, shift_samples), mode='constant')\n",
    "        elif shift_samples < 0:\n",
    "            aug = np.pad(aug[:shift_samples], (-shift_samples, 0), mode='constant')\n",
    "        \n",
    "        # Conservative pitch shift (50% probability)\n",
    "        if np.random.random() > 0.5:\n",
    "            n_steps = np.random.uniform(-0.5, 0.5)\n",
    "            try:\n",
    "                aug = librosa.effects.pitch_shift(aug, sr=sr, n_steps=n_steps)\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        # Light time stretching (50% probability)\n",
    "        if np.random.random() > 0.5:\n",
    "            rate = np.random.uniform(0.95, 1.05)\n",
    "            try:\n",
    "                aug = librosa.effects.time_stretch(aug, rate=rate)\n",
    "                # Trim or pad back to original length\n",
    "                if len(aug) > len(frame):\n",
    "                    aug = aug[:len(frame)]\n",
    "                else:\n",
    "                    aug = np.pad(aug, (0, len(frame) - len(aug)), mode='constant')\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        # Minimal noise (30% probability)\n",
    "        if np.random.random() > 0.7:\n",
    "            current_rms = compute_rms(aug)\n",
    "            noise_level = current_rms * 0.005\n",
    "            noise = np.random.normal(0, noise_level, len(aug))\n",
    "            aug = aug + noise\n",
    "        \n",
    "        # FIXED: Restore RMS with tighter tolerance (±5% instead of ±10%)\n",
    "        aug_rms = compute_rms(aug)\n",
    "        if aug_rms > 1e-8:\n",
    "            target_rms = original_rms * np.random.uniform(0.95, 1.05)\n",
    "            aug = aug * (target_rms / aug_rms)\n",
    "        \n",
    "        # Safety clipping\n",
    "        aug = handle_clipping(aug)\n",
    "        augmented.append(aug)\n",
    "    \n",
    "    return augmented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ab4534b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded exploration data: 843 files\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(EXPLORATION_CSV):\n",
    "    raise FileNotFoundError(f\"Exploration CSV not found: {EXPLORATION_CSV}\")\n",
    "\n",
    "df_expl = pd.read_csv(EXPLORATION_CSV)\n",
    "print(f\"\\nLoaded exploration data: {len(df_expl)} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "580467f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 40 duplicate files → 803 unique files\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "original_count = len(df_expl)\n",
    "df_expl = df_expl.drop_duplicates(subset='file_hash', keep='first')\n",
    "duplicates_removed = original_count - len(df_expl)\n",
    "print(f\"Removed {duplicates_removed} duplicate files → {len(df_expl)} unique files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1331e4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 803 files that loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Filter successful loads\n",
    "df_expl = df_expl[df_expl['load_success'] == True].copy()\n",
    "print(f\"Using {len(df_expl)} files that loaded successfully\")\n",
    "\n",
    "# Prepare output directories\n",
    "os.makedirs(PROCESSED_ROOT, exist_ok=True)\n",
    "for category in df_expl['category'].unique():\n",
    "    os.makedirs(os.path.join(PROCESSED_ROOT, category), exist_ok=True)\n",
    "\n",
    "# Initialize tracking\n",
    "processed_records = []\n",
    "stats = {\n",
    "    'files_processed': 0,\n",
    "    'files_skipped_silent': 0,\n",
    "    'files_skipped_error': 0,\n",
    "    'frames_original': 0,\n",
    "    'frames_augmented': 0,\n",
    "    'frames_skipped_silent': 0,\n",
    "    'frames_skipped_post_norm': 0\n",
    "}\n",
    "skipped_details = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "100751db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing files...\n",
      "Silence threshold: 0.015\n",
      "Min frame RMS after normalization: 0.01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 803/803 [01:13<00:00, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPROCESSING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Saved 7100 total frames\n",
      "  - Original frames: 3030\n",
      "  - Augmented frames: 4070\n",
      "  - Metadata: ../data/processed\\processed_frames_metadata.csv\n",
      "\n",
      "Frames per category:\n",
      "  Alarm_Clock    : 1296 (432 original + 864 augmented)\n",
      "  Car_Horn       : 1480 (740 original + 740 augmented)\n",
      "  Glass_Breaking : 1216 (304 original + 912 augmented)\n",
      "  Gunshot        : 1536 (768 original + 768 augmented)\n",
      "  Siren          : 1572 (786 original + 786 augmented)\n",
      "\n",
      "RMS Statistics by Category:\n",
      "                    mean       std       min       max\n",
      "category                                              \n",
      "Alarm_Clock     0.129290  0.020177  0.039896  0.146997\n",
      "Car_Horn        0.159343  0.024383  0.026693  0.178447\n",
      "Glass_Breaking  0.088367  0.019063  0.022397  0.104994\n",
      "Gunshot         0.141693  0.030626  0.032118  0.167980\n",
      "Siren           0.184815  0.018496  0.063129  0.199414\n",
      "\n",
      "RMS Target Achievement:\n",
      "  ✓ Alarm_Clock    : Target=0.140, Actual=0.129 (92.3%)\n",
      "  ✓ Car_Horn       : Target=0.170, Actual=0.159 (93.7%)\n",
      "  ⚠ Glass_Breaking : Target=0.100, Actual=0.088 (88.4%)\n",
      "  ⚠ Gunshot        : Target=0.160, Actual=0.142 (88.6%)\n",
      "  ✓ Siren          : Target=0.190, Actual=0.185 (97.3%)\n",
      "\n",
      "Class balance ratio: 1.29 (max/min)\n",
      "Dataset is well balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nProcessing files...\")\n",
    "print(f\"Silence threshold: {SILENCE_RMS_THR}\")\n",
    "print(f\"Min frame RMS after normalization: {MIN_FRAME_RMS}\\n\")\n",
    "\n",
    "# Process each file\n",
    "for _, row in tqdm(df_expl.iterrows(), total=len(df_expl), desc=\"Processing\"):\n",
    "    category = row['category']\n",
    "    filename = row['file']\n",
    "    filepath = os.path.join(DATA_DIR, category, filename)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        stats['files_skipped_error'] += 1\n",
    "        skipped_details.append(f\"{filename}: File not found\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. Load audio (mono, 16kHz)\n",
    "        y, sr = load_audio(filepath)\n",
    "        \n",
    "        # 2. Check for silence at file level\n",
    "        if is_silent(y):\n",
    "            stats['files_skipped_silent'] += 1\n",
    "            skipped_details.append(f\"{filename}: Silent file (RMS={compute_rms(y):.6f})\")\n",
    "            continue\n",
    "        \n",
    "        # REMOVED: SNR filtering was too aggressive for clean AudioSet data\n",
    "        # It filtered out 94.5% of Siren files based on estimation artifacts\n",
    "        \n",
    "        # 3. Handle clipping\n",
    "        y = handle_clipping(y)\n",
    "        \n",
    "        # 4. Pad if needed\n",
    "        y = pad_to_length(y, sr)\n",
    "        \n",
    "        stats['files_processed'] += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        stats['files_skipped_error'] += 1\n",
    "        skipped_details.append(f\"{filename}: Error loading - {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    # FRAME-LEVEL PROCESSING\n",
    "    frames = extract_frames(y, sr)\n",
    "    augment_factor = AUGMENT_MULTIPLIERS.get(category, 2)\n",
    "    target_rms = CATEGORY_RMS_TARGETS.get(category, 0.15)\n",
    "    \n",
    "    for frame_idx, frame in enumerate(frames):\n",
    "        # Check frame for silence BEFORE normalization\n",
    "        if is_silent(frame):\n",
    "            stats['frames_skipped_silent'] += augment_factor\n",
    "            continue\n",
    "        \n",
    "        # Normalize frame\n",
    "        frame_normalized = normalise_rms(frame, target_rms, max_gain=4.0)\n",
    "        frame_normalized = handle_clipping(frame_normalized)\n",
    "        \n",
    "        # Additional check after normalization\n",
    "        # Ensure frame actually reached a reasonable RMS\n",
    "        final_rms = compute_rms(frame_normalized)\n",
    "        if final_rms < MIN_FRAME_RMS:\n",
    "            stats['frames_skipped_post_norm'] += augment_factor\n",
    "            continue\n",
    "        \n",
    "        # Generate augmented versions\n",
    "        augmented_frames = augment_frame(frame_normalized, sr, category, augment_factor)\n",
    "        \n",
    "        for aug_idx, aug_frame in enumerate(augmented_frames):\n",
    "            # Final safety clipping\n",
    "            aug_frame = handle_clipping(aug_frame)\n",
    "            \n",
    "            # Verify augmented frame quality\n",
    "            aug_rms = compute_rms(aug_frame)\n",
    "            if aug_rms < MIN_FRAME_RMS:\n",
    "                continue  # Skip this augmented frame\n",
    "            \n",
    "            # Save frame\n",
    "            frame_name = f\"{os.path.splitext(filename)[0]}_f{frame_idx}_a{aug_idx}.npy\"\n",
    "            cat_out_dir = os.path.join(PROCESSED_ROOT, category)\n",
    "            frame_path = os.path.join(cat_out_dir, frame_name)\n",
    "            np.save(frame_path, aug_frame)\n",
    "            \n",
    "            # Record metadata\n",
    "            processed_records.append({\n",
    "                'category': category,\n",
    "                'original_file': filename,\n",
    "                'frame_idx': frame_idx,\n",
    "                'aug_idx': aug_idx,\n",
    "                'is_augmented': aug_idx > 0,\n",
    "                'frame_path': frame_path,\n",
    "                'duration_sec': FRAME_SEC,\n",
    "                'rms': aug_rms\n",
    "            })\n",
    "            \n",
    "            if aug_idx == 0:\n",
    "                stats['frames_original'] += 1\n",
    "            else:\n",
    "                stats['frames_augmented'] += 1\n",
    "\n",
    "# Save metadata\n",
    "meta_df = pd.DataFrame(processed_records)\n",
    "meta_path = os.path.join(PROCESSED_ROOT, 'processed_frames_metadata.csv')\n",
    "meta_df.to_csv(meta_path, index=False)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nSaved {len(meta_df)} total frames\")\n",
    "print(f\"  - Original frames: {stats['frames_original']}\")\n",
    "print(f\"  - Augmented frames: {stats['frames_augmented']}\")\n",
    "print(f\"  - Metadata: {meta_path}\")\n",
    "\n",
    "print(f\"\\nFrames per category:\")\n",
    "category_counts = meta_df['category'].value_counts().sort_index()\n",
    "for cat, count in category_counts.items():\n",
    "    orig = len(meta_df[(meta_df['category'] == cat) & (meta_df['aug_idx'] == 0)])\n",
    "    aug = count - orig\n",
    "    print(f\"  {cat:15s}: {count:4d} ({orig} original + {aug} augmented)\")\n",
    "\n",
    "# RMS statistics\n",
    "print(f\"\\nRMS Statistics by Category:\")\n",
    "rms_stats = meta_df.groupby('category')['rms'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(rms_stats)\n",
    "\n",
    "# Check if targets were reached\n",
    "print(f\"\\nRMS Target Achievement:\")\n",
    "for cat in category_counts.index:\n",
    "    target = CATEGORY_RMS_TARGETS.get(cat, 0.15)\n",
    "    actual = meta_df[meta_df['category'] == cat]['rms'].mean()\n",
    "    ratio = (actual / target) * 100\n",
    "    status = \"✓\" if ratio >= 90 else \"⚠\"\n",
    "    print(f\"  {status} {cat:15s}: Target={target:.3f}, Actual={actual:.3f} ({ratio:.1f}%)\")\n",
    "\n",
    "# Class balance\n",
    "max_count = category_counts.max()\n",
    "min_count = category_counts.min()\n",
    "balance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "print(f\"\\nClass balance ratio: {balance_ratio:.2f} (max/min)\")\n",
    "if balance_ratio > 1.5:\n",
    "    print(f\"Dataset has some imbalance (ratio > 1.5)\")\n",
    "else:\n",
    "    print(f\"Dataset is well balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "534835b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File processing:\n",
      "  - Processed: 773\n",
      "  - Skipped (silent): 30\n",
      "  - Skipped (error): 0\n",
      "\n",
      "Frame filtering:\n",
      "  - Frames skipped (silent): 1466\n",
      "  - Frames skipped (post-norm too quiet): 0\n",
      "\n",
      "Skipped files details (first 15):\n",
      "  - -74dab6wYqU_30.wav: Silent file (RMS=0.002488)\n",
      "  - -eQkuW-SGkA_30.wav: Silent file (RMS=0.009133)\n",
      "  - 5CYK7AKivDo_180.wav: Silent file (RMS=0.007945)\n",
      "  - 9gEGGTWHOjU_10.wav: Silent file (RMS=0.011665)\n",
      "  - BldrjFV90H0_50.wav: Silent file (RMS=0.014469)\n",
      "  - CijrnO-HHGo_10.wav: Silent file (RMS=0.007601)\n",
      "  - CYgCdPSDuLU_30.wav: Silent file (RMS=0.008393)\n",
      "  - EDzycaY5D_Y_50.wav: Silent file (RMS=0.011952)\n",
      "  - FXrlR_YbiNU_30.wav: Silent file (RMS=0.010852)\n",
      "  - IZH2Npv-TB4_0.wav: Silent file (RMS=0.013739)\n",
      "  - KlhaNw2GOdI_30.wav: Silent file (RMS=0.012178)\n",
      "  - Nc2S-9oUB8M_70.wav: Silent file (RMS=0.007312)\n",
      "  - Ogx6MVJ9gOo_340.wav: Silent file (RMS=0.008449)\n",
      "  - Glass_Breaking_108.wav: Silent file (RMS=0.009846)\n",
      "  - Glass_Breaking_11.wav: Silent file (RMS=0.011350)\n",
      "  ... and 15 more\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFile processing:\")\n",
    "print(f\"  - Processed: {stats['files_processed']}\")\n",
    "print(f\"  - Skipped (silent): {stats['files_skipped_silent']}\")\n",
    "print(f\"  - Skipped (error): {stats['files_skipped_error']}\")\n",
    "\n",
    "print(f\"\\nFrame filtering:\")\n",
    "print(f\"  - Frames skipped (silent): {stats['frames_skipped_silent']}\")\n",
    "print(f\"  - Frames skipped (post-norm too quiet): {stats['frames_skipped_post_norm']}\")\n",
    "\n",
    "if skipped_details:\n",
    "    print(f\"\\nSkipped files details (first 15):\")\n",
    "    for detail in skipped_details[:15]:\n",
    "        print(f\"  - {detail}\")\n",
    "    if len(skipped_details) > 15:\n",
    "        print(f\"  ... and {len(skipped_details) - 15} more\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
